import { useState, useRef, useEffect, useCallback } from 'react';
import { Mic, MicOff, Loader2, AlertCircle, CheckCircle2, Trash2, Volume2, Clock, Layers } from 'lucide-react';
import { useSemaphore } from '../hooks/useProcessingQueue';

type Status = 'checking' | 'available' | 'unavailable' | 'recording';

interface TranscriptChunk {
  id: string;
  text: string;
  timestamp: Date;
  isProcessing: boolean;
}

export function AudioTranscription() {
  const [status, setStatus] = useState<Status>('checking');
  const [error, setError] = useState<string | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [transcripts, setTranscripts] = useState<TranscriptChunk[]>([]);

  // éŸ³å£°ãƒ¬ãƒ™ãƒ«å¯è¦–åŒ–ç”¨
  const [audioLevel, setAudioLevel] = useState(0);
  const [isSpeaking, setIsSpeaking] = useState(false);

  // éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰
  const [recordingMode, setRecordingMode] = useState<'vad' | 'fixed'>('vad');
  const [fixedDuration, setFixedDuration] = useState(5); // å›ºå®šéŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
  const [currentChunkTime, setCurrentChunkTime] = useState(0);

  // éŸ³å£°è¨­å®šï¼ˆèª¿æ•´å¯èƒ½ï¼‰
  const [inputGain, setInputGain] = useState(1.0); // ã‚²ã‚¤ãƒ³ï¼ˆ0.1ã€œ3.0ï¼‰
  const [silenceThreshold, setSilenceThreshold] = useState(15); // ç„¡éŸ³é–¾å€¤ï¼ˆ0ã€œ100ï¼‰
  const [silenceDuration, setSilenceDuration] = useState(1500); // ç„¡éŸ³ç¶™ç¶šæ™‚é–“ï¼ˆmsï¼‰

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const transcriptsEndRef = useRef<HTMLDivElement>(null);
  const isRecordingRef = useRef(false);
  const mimeTypeRef = useRef<string>('audio/webm');

  // éŸ³å£°è§£æç”¨
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const silenceStartRef = useRef<number | null>(null);
  const hasSpokenRef = useRef(false);
  const recordingStartTimeRef = useRef<number>(0);
  const gainNodeRef = useRef<GainNode | null>(null);
  const timerRef = useRef<number | null>(null);

  // ä¸¦åˆ—å‡¦ç†åˆ¶å¾¡
  const [maxConcurrentProcessing, setMaxConcurrentProcessing] = useState(2);
  const processSemaphore = useSemaphore(maxConcurrentProcessing);
  const [processingQueueSize, setProcessingQueueSize] = useState(0);
  const [activeProcessingCount, setActiveProcessingCount] = useState(0);
  const pendingChunksRef = useRef<Blob[]>([]);
  const isProcessingQueueRef = useRef(false);

  // å›ºå®šè¨­å®š
  const MIN_RECORDING_DURATION = 500; // æœ€å°éŒ²éŸ³æ™‚é–“ï¼ˆmsï¼‰

  // APIã®å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
  const checkAvailability = useCallback(async () => {
    setStatus('checking');
    setError(null);

    if (typeof LanguageModel === 'undefined') {
      setStatus('unavailable');
      setError('LanguageModel APIãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
      return;
    }

    try {
      const availability = await LanguageModel.availability({
        expectedInputs: [{ type: 'audio' }],
      });
      console.log('Audio API Availability:', availability);

      if (availability === 'available' || availability === 'readily') {
        setStatus('available');
      } else if (availability === 'downloadable' || availability === 'after-download') {
        setStatus('checking');
        const tempSession = await LanguageModel.create({
          expectedInputs: [{ type: 'audio' }],
          expectedOutputLanguages: ['ja'],
        });
        tempSession.destroy();
        setStatus('available');
      } else {
        setStatus('unavailable');
        setError(`éŸ³å£°APIåˆ©ç”¨ä¸å¯: ${availability}`);
      }
    } catch (e) {
      setStatus('unavailable');
      setError(e instanceof Error ? e.message : 'Unknown error');
    }
  }, []);

  useEffect(() => {
    checkAvailability();
  }, [checkAvailability]);

  useEffect(() => {
    transcriptsEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [transcripts]);

  // ã‚²ã‚¤ãƒ³å¤‰æ›´æ™‚ã«GainNodeã‚’æ›´æ–°
  useEffect(() => {
    if (gainNodeRef.current) {
      gainNodeRef.current.gain.value = inputGain;
    }
  }, [inputGain]);

  // Blobã‚’ArrayBufferã«å¤‰æ›
  const blobToArrayBuffer = async (blob: Blob): Promise<ArrayBuffer> => {
    return await blob.arrayBuffer();
  };

  // JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰transcriptionã‚’æŠ½å‡ºã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
  const extractTranscription = (response: string): string => {
    console.log('Raw response:', response);

    // å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    const trimmed = response.trim();

    // 1. ã¾ãšé€šå¸¸ã®JSONãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
    try {
      const parsed = JSON.parse(trimmed);
      if (typeof parsed.transcription === 'string') {
        return parsed.transcription;
      }
    } catch {
      // ãƒ‘ãƒ¼ã‚¹å¤±æ•—
    }

    // 2. ä¸å®Œå…¨ãªJSONã®å ´åˆã€é–‰ã˜æ‹¬å¼§ã‚’è¿½åŠ ã—ã¦ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
    if (trimmed.startsWith('{"transcription"') && !trimmed.endsWith('}')) {
      try {
        // æœ«å°¾ã®æ”¹è¡Œã‚„ä¸å®Œå…¨ãªå¼•ç”¨ç¬¦ã‚’å‡¦ç†
        let fixed = trimmed;
        if (!fixed.endsWith('"')) {
          fixed = fixed + '"';
        }
        fixed = fixed + '}';
        const parsed = JSON.parse(fixed);
        if (typeof parsed.transcription === 'string') {
          return parsed.transcription;
        }
      } catch {
        // ãƒ‘ãƒ¼ã‚¹å¤±æ•—
      }
    }

    // 3. "transcription": "..." ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ­£è¦è¡¨ç¾ã§æŠ½å‡º
    const match = trimmed.match(/"transcription"\s*:\s*"((?:[^"\\]|\\.)*)"/);
    if (match && match[1]) {
      // ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚ŒãŸæ–‡å­—ã‚’å‡¦ç†
      return match[1].replace(/\\n/g, '\n').replace(/\\"/g, '"').replace(/\\\\/g, '\\');
    }

    // 4. {"transcription": ã®å¾Œã®æ–‡å­—åˆ—ã‚’ç›´æ¥æŠ½å‡º
    const prefixMatch = trimmed.match(/^\{"transcription"\s*:\s*"(.*)$/s);
    if (prefixMatch && prefixMatch[1]) {
      // æœ«å°¾ã® "}ã‚„æ”¹è¡Œã‚’å‰Šé™¤
      let extracted = prefixMatch[1];
      extracted = extracted.replace(/"\s*}?\s*$/, '');
      extracted = extracted.replace(/\\n/g, '\n').replace(/\\"/g, '"').replace(/\\\\/g, '\\');
      return extracted;
    }

    // 5. ä½•ã‚‚æŠ½å‡ºã§ããªã„å ´åˆã¯å…ƒã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ï¼ˆJSONãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»ï¼‰
    if (trimmed.startsWith('{"transcription"')) {
      return trimmed.replace(/^\{"transcription"\s*:\s*"?/, '').replace(/"?\s*}?$/, '');
    }

    return trimmed;
  };

  // éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆã‚»ãƒãƒ•ã‚©ã§åŒæ™‚å®Ÿè¡Œæ•°ã‚’åˆ¶å¾¡ï¼‰
  const transcribeChunkInternal = async (audioBlob: Blob, chunkId: string) => {
    let session: LanguageModelSession | null = null;

    try {
      // æ¯å›æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆï¼ˆæ§‹é€ åŒ–ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆï¼‰
      session = await LanguageModel.create({
        expectedInputs: [{ type: 'audio' }],
        expectedOutputLanguages: ['ja'],
        systemPrompt: 'éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ã€transcriptionãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«çµæœã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚éŸ³å£°ãŒèãå–ã‚Œãªã„å ´åˆã¯ç©ºæ–‡å­—ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚',
      });

      // ArrayBufferã«å¤‰æ›
      const arrayBuffer = await blobToArrayBuffer(audioBlob);
      console.log('Audio buffer size:', arrayBuffer.byteLength);

      // æ§‹é€ åŒ–ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆç”¨ã®JSON Schema
      const transcriptionSchema = {
        type: 'object',
        properties: {
          transcription: { type: 'string', description: 'éŸ³å£°ã®æ–‡å­—èµ·ã“ã—çµæœ' },
        },
        required: ['transcription'],
        additionalProperties: false,
      };

      const rawResponse = await session.prompt(
        [
          {
            role: 'user',
            content: [
              { type: 'text', value: 'ã“ã®éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ï¼š' },
              { type: 'audio', value: arrayBuffer },
            ],
          },
        ],
        { responseConstraint: transcriptionSchema }
      );

      // JSONã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
      const transcription = extractTranscription(rawResponse);
      console.log('Extracted transcription:', transcription);

      setTranscripts(prev =>
        prev.map(t =>
          t.id === chunkId
            ? { ...t, text: transcription, isProcessing: false }
            : t
        )
      );
    } catch (e) {
      console.error('Transcription error:', e);
      setTranscripts(prev =>
        prev.map(t =>
          t.id === chunkId
            ? { ...t, text: `ã‚¨ãƒ©ãƒ¼: ${e instanceof Error ? e.message : 'Unknown'}`, isProcessing: false }
            : t
        )
      );
    } finally {
      // ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å¿…ãšç ´æ£„
      if (session) {
        session.destroy();
      }
    }
  };

  // ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
  const processQueue = useCallback(async () => {
    if (isProcessingQueueRef.current) return;
    isProcessingQueueRef.current = true;

    while (pendingChunksRef.current.length > 0) {
      const audioBlob = pendingChunksRef.current.shift();
      if (!audioBlob) continue;

      setProcessingQueueSize(pendingChunksRef.current.length);

      // ã‚»ãƒãƒ•ã‚©ã§åŒæ™‚å®Ÿè¡Œæ•°ã‚’åˆ¶é™
      await processSemaphore.withSemaphore(async () => {
        setActiveProcessingCount(prev => prev + 1);
        const chunkId = crypto.randomUUID();

        setTranscripts(prev => [...prev, {
          id: chunkId,
          text: '',
          timestamp: new Date(),
          isProcessing: true,
        }]);

        try {
          await transcribeChunkInternal(audioBlob, chunkId);
        } finally {
          setActiveProcessingCount(prev => Math.max(0, prev - 1));
        }
      });
    }

    isProcessingQueueRef.current = false;
  }, [processSemaphore]);

  // éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
  const enqueueChunk = useCallback((audioBlob: Blob) => {
    if (audioBlob.size < 1000) {
      console.log('Audio chunk too small, skipping:', audioBlob.size);
      return;
    }

    pendingChunksRef.current.push(audioBlob);
    setProcessingQueueSize(pendingChunksRef.current.length);
    console.log(`Enqueued chunk (queue size: ${pendingChunksRef.current.length})`);

    // ã‚­ãƒ¥ãƒ¼å‡¦ç†ã‚’é–‹å§‹
    processQueue();
  }, [processQueue]);

  // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ç›£è¦–
  const startAudioAnalysis = () => {
    if (!analyserRef.current) return;

    const analyser = analyserRef.current;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    const analyze = () => {
      if (!isRecordingRef.current) return;

      analyser.getByteFrequencyData(dataArray);

      // å¹³å‡éŸ³é‡ã‚’è¨ˆç®—
      const average = dataArray.reduce((a, b) => a + b, 0) / bufferLength;
      setAudioLevel(Math.min(100, (average / 128) * 100));

      // VADãƒ¢ãƒ¼ãƒ‰ã®ã¿ç„¡éŸ³æ¤œå‡ºã‚’è¡Œã†
      if (recordingMode === 'vad') {
        const now = Date.now();
        const recordingDuration = now - recordingStartTimeRef.current;

        if (average > silenceThreshold) {
          // éŸ³å£°æ¤œå‡º
          setIsSpeaking(true);
          hasSpokenRef.current = true;
          silenceStartRef.current = null;
        } else {
          // ç„¡éŸ³
          setIsSpeaking(false);

          if (hasSpokenRef.current && recordingDuration > MIN_RECORDING_DURATION) {
            // ç™ºè©±å¾Œã®ç„¡éŸ³ã‚’æ¤œå‡º
            if (silenceStartRef.current === null) {
              silenceStartRef.current = now;
            } else if (now - silenceStartRef.current > silenceDuration) {
              // ç„¡éŸ³ãŒä¸€å®šæ™‚é–“ç¶šã„ãŸã‚‰éŒ²éŸ³åœæ­¢
              console.log('Silence detected, stopping current recording');
              if (mediaRecorderRef.current?.state === 'recording') {
                mediaRecorderRef.current.stop();
              }
              return; // æ¬¡ã®analyzeã¯å‘¼ã°ãªã„
            }
          }
        }
      } else {
        // å›ºå®šãƒ¢ãƒ¼ãƒ‰ã§ã¯éŸ³å£°ãƒ¬ãƒ™ãƒ«ã®ã¿è¡¨ç¤º
        setIsSpeaking(average > silenceThreshold);
      }

      animationFrameRef.current = requestAnimationFrame(analyze);
    };

    analyze();
  };

  // æ–°ã—ã„MediaRecorderã‚’ä½œæˆï¼ˆéŸ³å£°æ¤œå‡ºãƒ™ãƒ¼ã‚¹ or å›ºå®šæ™‚é–“ï¼‰
  const startNewRecorder = () => {
    if (!streamRef.current || !isRecordingRef.current) return;

    chunksRef.current = [];
    hasSpokenRef.current = false;
    silenceStartRef.current = null;
    recordingStartTimeRef.current = Date.now();
    setCurrentChunkTime(0);

    // å‰ã®ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }

    const mediaRecorder = new MediaRecorder(streamRef.current, {
      mimeType: mimeTypeRef.current
    });
    mediaRecorderRef.current = mediaRecorder;

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        chunksRef.current.push(event.data);
      }
    };

    mediaRecorder.onstop = () => {
      // ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
      setCurrentChunkTime(0);

      // éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ï¼ˆVADãƒ¢ãƒ¼ãƒ‰ã¯ç™ºè©±ãŒã‚ã£ãŸå ´åˆã®ã¿ã€å›ºå®šãƒ¢ãƒ¼ãƒ‰ã¯å¸¸ã«å‡¦ç†ï¼‰
      const shouldProcess = recordingMode === 'fixed' || hasSpokenRef.current;
      if (chunksRef.current.length > 0 && shouldProcess) {
        const audioBlob = new Blob(chunksRef.current, { type: mimeTypeRef.current });
        console.log('Enqueuing audio chunk:', audioBlob.size, 'bytes');

        if (audioBlob.size >= 1000) {
          // ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ï¼ˆä¸¦åˆ—å‡¦ç†åˆ¶å¾¡ï¼‰
          enqueueChunk(audioBlob);
        } else {
          console.log('Audio chunk too small, skipping');
        }
      }

      // ã¾ã éŒ²éŸ³ä¸­ãªã‚‰æ–°ã—ã„ãƒ¬ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’é–‹å§‹ï¼ˆå‡¦ç†å®Œäº†ã‚’å¾…ãŸãšã«å³åº§ã«é–‹å§‹ï¼‰
      if (isRecordingRef.current) {
        startNewRecorder();
      }
    };

    // 100msã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    mediaRecorder.start(100);

    if (recordingMode === 'vad') {
      console.log('Started new recorder (voice-activated)');
      // éŸ³å£°è§£æé–‹å§‹
      startAudioAnalysis();
    } else {
      console.log(`Started new recorder (fixed ${fixedDuration}s)`);
      // å›ºå®šãƒ¢ãƒ¼ãƒ‰ã§ã¯å³åº§ã«hasSpokenã‚’trueã«
      hasSpokenRef.current = true;
      // ã‚¿ã‚¤ãƒãƒ¼ã§å›ºå®šæ™‚é–“å¾Œã«åœæ­¢
      let count = 0;
      timerRef.current = window.setInterval(() => {
        count++;
        setCurrentChunkTime(count);
        if (count >= fixedDuration) {
          if (timerRef.current) {
            clearInterval(timerRef.current);
            timerRef.current = null;
          }
          if (mediaRecorderRef.current?.state === 'recording') {
            console.log('Fixed duration reached, stopping recording');
            mediaRecorderRef.current.stop();
          }
        }
      }, 1000);
      // éŸ³å£°è§£æé–‹å§‹ï¼ˆãƒ¬ãƒ™ãƒ«è¡¨ç¤ºç”¨ï¼‰
      startAudioAnalysis();
    }
  };

  // éŒ²éŸ³é–‹å§‹
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 16000,
        }
      });
      streamRef.current = stream;

      // AudioContextã¨AnalyserNodeã€GainNodeã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
      audioContextRef.current = new AudioContext();
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 256;
      analyserRef.current.smoothingTimeConstant = 0.8;

      // GainNodeã‚’ä½œæˆã—ã¦ã‚²ã‚¤ãƒ³ã‚’é©ç”¨
      gainNodeRef.current = audioContextRef.current.createGain();
      gainNodeRef.current.gain.value = inputGain;

      const source = audioContextRef.current.createMediaStreamSource(stream);
      source.connect(gainNodeRef.current);
      gainNodeRef.current.connect(analyserRef.current);

      // ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹MIMEã‚¿ã‚¤ãƒ—ã‚’ç¢ºèª
      mimeTypeRef.current = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : MediaRecorder.isTypeSupported('audio/webm')
          ? 'audio/webm'
          : 'audio/mp4';

      console.log('Using MIME type:', mimeTypeRef.current);

      setIsRecording(true);
      isRecordingRef.current = true;
      setStatus('recording');

      // æœ€åˆã®ãƒ¬ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’é–‹å§‹
      startNewRecorder();
    } catch (e) {
      console.error('Recording error:', e);
      setError(e instanceof Error ? e.message : 'ãƒã‚¤ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“');
    }
  };

  // éŒ²éŸ³åœæ­¢
  const stopRecording = () => {
    isRecordingRef.current = false;

    // ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }

    // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop(); // onstopã§æ®‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
    }

    // AudioContextã‚’ã‚¯ãƒ­ãƒ¼ã‚º
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    setIsRecording(false);
    setIsSpeaking(false);
    setAudioLevel(0);
    setCurrentChunkTime(0);
    setStatus('available');
  };

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      isRecordingRef.current = false;
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  const clearTranscripts = () => {
    setTranscripts([]);
    // ã‚­ãƒ¥ãƒ¼ã‚‚ã‚¯ãƒªã‚¢
    pendingChunksRef.current = [];
    setProcessingQueueSize(0);
  };

  const getFullTranscript = () => {
    return transcripts
      .filter(t => !t.isProcessing && !t.text.startsWith('ã‚¨ãƒ©ãƒ¼'))
      .map(t => t.text)
      .join(' ');
  };

  return (
    <div className="flex flex-col h-full">
      {/* Header */}
      <div className="flex items-center justify-between p-4 border-b border-[hsl(var(--border))]">
        <h1 className="text-lg font-semibold">éŸ³å£°æ–‡å­—èµ·ã“ã—</h1>
        <div className="flex items-center gap-3">
          <div className={`flex items-center gap-2 px-3 py-1.5 rounded-full text-xs ${
            status === 'checking' ? 'bg-yellow-500/20 text-yellow-400' :
            status === 'available' ? 'bg-green-500/20 text-green-400' :
            status === 'recording' ? 'bg-red-500/20 text-red-400' :
            'bg-red-500/20 text-red-400'
          }`}>
            {status === 'checking' && <Loader2 className="w-4 h-4 animate-spin" />}
            {status === 'available' && <CheckCircle2 className="w-4 h-4" />}
            {status === 'recording' && <Mic className="w-4 h-4 animate-pulse" />}
            {status === 'unavailable' && <AlertCircle className="w-4 h-4" />}
            <span>
              {status === 'checking' && 'ç¢ºèªä¸­...'}
              {status === 'available' && 'æº–å‚™å®Œäº†'}
              {status === 'recording' && (
              recordingMode === 'fixed'
                ? `â±ï¸ éŒ²éŸ³ä¸­... ${currentChunkTime}/${fixedDuration}ç§’`
                : (isSpeaking ? 'ğŸ¤ ç™ºè©±æ¤œå‡ºä¸­...' : 'ğŸ”‡ å¾…æ©Ÿä¸­...')
            )}
              {status === 'unavailable' && (error || 'APIåˆ©ç”¨ä¸å¯')}
            </span>
          </div>
          {transcripts.length > 0 && (
            <button
              onClick={clearTranscripts}
              className="text-xs text-[hsl(var(--muted-foreground))] hover:text-[hsl(var(--foreground))] transition-colors flex items-center gap-1"
            >
              <Trash2 className="w-3 h-3" />
              ã‚¯ãƒªã‚¢
            </button>
          )}
        </div>
      </div>

      {/* éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ */}
      <div className="p-4 border-b border-[hsl(var(--border))] bg-[hsl(var(--secondary)/0.3)]">
        <h3 className="text-xs font-medium text-[hsl(var(--muted-foreground))] mb-3">éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰</h3>
        <div className="flex gap-2 mb-3">
          <button
            onClick={() => setRecordingMode('vad')}
            disabled={isRecording}
            className={`flex-1 px-3 py-2 rounded-lg text-sm transition-all ${
              recordingMode === 'vad'
                ? 'bg-purple-500 text-white'
                : 'bg-[hsl(var(--secondary))] text-[hsl(var(--muted-foreground))] hover:bg-[hsl(var(--secondary)/0.8)]'
            } disabled:opacity-50`}
          >
            éŸ³å£°æ¤œå‡ºï¼ˆVADï¼‰
          </button>
          <button
            onClick={() => setRecordingMode('fixed')}
            disabled={isRecording}
            className={`flex-1 px-3 py-2 rounded-lg text-sm transition-all ${
              recordingMode === 'fixed'
                ? 'bg-purple-500 text-white'
                : 'bg-[hsl(var(--secondary))] text-[hsl(var(--muted-foreground))] hover:bg-[hsl(var(--secondary)/0.8)]'
            } disabled:opacity-50`}
          >
            å›ºå®šæ™‚é–“
          </button>
        </div>
        {recordingMode === 'fixed' && (
          <div className="space-y-1">
            <div className="flex justify-between items-center">
              <label className="text-xs text-[hsl(var(--muted-foreground))]">éŒ²éŸ³æ™‚é–“</label>
              <span className="text-xs font-mono text-[hsl(var(--foreground))]">{fixedDuration}ç§’</span>
            </div>
            <input
              type="range"
              min="3"
              max="30"
              step="1"
              value={fixedDuration}
              onChange={(e) => setFixedDuration(parseInt(e.target.value))}
              disabled={isRecording}
              className="w-full h-2 bg-[hsl(var(--secondary))] rounded-lg appearance-none cursor-pointer accent-purple-500 disabled:opacity-50"
            />
            <div className="flex justify-between text-[10px] text-[hsl(var(--muted-foreground))]">
              <span>3ç§’</span>
              <span>30ç§’</span>
            </div>
          </div>
        )}
      </div>

      {/* ä¸¦åˆ—å‡¦ç†è¨­å®š */}
      <div className="p-4 border-b border-[hsl(var(--border))] bg-[hsl(var(--secondary)/0.3)]">
        <h3 className="text-xs font-medium text-[hsl(var(--muted-foreground))] flex items-center gap-1 mb-3">
          <Layers className="w-3 h-3" />
          ä¸¦åˆ—å‡¦ç†è¨­å®š
        </h3>
        <div className="flex items-center gap-4">
          <div className="flex items-center gap-2">
            <span className="text-xs text-[hsl(var(--muted-foreground))]">åŒæ™‚å‡¦ç†æ•°:</span>
            <select
              value={maxConcurrentProcessing}
              onChange={(e) => setMaxConcurrentProcessing(parseInt(e.target.value))}
              disabled={isRecording}
              className="px-2 py-1 rounded-md border border-[hsl(var(--border))] bg-[hsl(var(--background))] text-[hsl(var(--foreground))] text-xs disabled:opacity-50"
            >
              <option value="1">1ï¼ˆé †æ¬¡å‡¦ç†ï¼‰</option>
              <option value="2">2ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰</option>
              <option value="3">3</option>
              <option value="4">4ï¼ˆé«˜é€Ÿï¼‰</option>
            </select>
          </div>
          {(processingQueueSize > 0 || activeProcessingCount > 0) && (
            <div className="flex items-center gap-3 text-xs">
              <span className="flex items-center gap-1 text-blue-400">
                <Loader2 className="w-3 h-3 animate-spin" />
                å‡¦ç†ä¸­: {activeProcessingCount}
              </span>
              {processingQueueSize > 0 && (
                <span className="flex items-center gap-1 text-yellow-400">
                  <Clock className="w-3 h-3" />
                  å¾…æ©Ÿä¸­: {processingQueueSize}
                </span>
              )}
            </div>
          )}
        </div>
      </div>

      {/* éŸ³å£°è¨­å®šï¼ˆVADãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿è©³ç´°è¡¨ç¤ºï¼‰ */}
      <div className="p-4 border-b border-[hsl(var(--border))] bg-[hsl(var(--secondary)/0.3)]">
        <h3 className="text-xs font-medium text-[hsl(var(--muted-foreground))] flex items-center gap-1 mb-3">
          <Volume2 className="w-3 h-3" />
          éŸ³å£°æ¤œå‡ºè¨­å®š
        </h3>
        <div className={`grid gap-4 ${recordingMode === 'vad' ? 'grid-cols-3' : 'grid-cols-1'}`}>
          {/* å…¥åŠ›ã‚²ã‚¤ãƒ³ */}
          <div className="space-y-1">
            <div className="flex justify-between items-center">
              <label className="text-xs text-[hsl(var(--muted-foreground))]">å…¥åŠ›ã‚²ã‚¤ãƒ³</label>
              <span className="text-xs font-mono text-[hsl(var(--foreground))]">{inputGain.toFixed(1)}x</span>
            </div>
            <input
              type="range"
              min="0.1"
              max="3.0"
              step="0.1"
              value={inputGain}
              onChange={(e) => setInputGain(parseFloat(e.target.value))}
              className="w-full h-2 bg-[hsl(var(--secondary))] rounded-lg appearance-none cursor-pointer accent-purple-500"
            />
            <div className="flex justify-between text-[10px] text-[hsl(var(--muted-foreground))]">
              <span>0.1x</span>
              <span>3.0x</span>
            </div>
          </div>

          {/* ç„¡éŸ³é–¾å€¤ï¼ˆVADãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰ */}
          {recordingMode === 'vad' && (
            <div className="space-y-1">
              <div className="flex justify-between items-center">
                <label className="text-xs text-[hsl(var(--muted-foreground))]">ç„¡éŸ³é–¾å€¤</label>
                <span className="text-xs font-mono text-[hsl(var(--foreground))]">{silenceThreshold}</span>
              </div>
              <input
                type="range"
                min="1"
                max="100"
                step="1"
                value={silenceThreshold}
                onChange={(e) => setSilenceThreshold(parseInt(e.target.value))}
                className="w-full h-2 bg-[hsl(var(--secondary))] rounded-lg appearance-none cursor-pointer accent-purple-500"
              />
              <div className="flex justify-between text-[10px] text-[hsl(var(--muted-foreground))]">
                <span>æ•æ„Ÿ</span>
                <span>éˆæ„Ÿ</span>
              </div>
            </div>
          )}

          {/* ç„¡éŸ³ç¶™ç¶šæ™‚é–“ï¼ˆVADãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰ */}
          {recordingMode === 'vad' && (
            <div className="space-y-1">
              <div className="flex justify-between items-center">
                <label className="text-xs text-[hsl(var(--muted-foreground))]">ç„¡éŸ³ç¶™ç¶šæ™‚é–“</label>
                <span className="text-xs font-mono text-[hsl(var(--foreground))]">{(silenceDuration / 1000).toFixed(1)}s</span>
              </div>
              <input
                type="range"
                min="500"
                max="5000"
                step="100"
                value={silenceDuration}
                onChange={(e) => setSilenceDuration(parseInt(e.target.value))}
                className="w-full h-2 bg-[hsl(var(--secondary))] rounded-lg appearance-none cursor-pointer accent-purple-500"
              />
              <div className="flex justify-between text-[10px] text-[hsl(var(--muted-foreground))]">
                <span>0.5s</span>
                <span>5.0s</span>
              </div>
            </div>
          )}
        </div>
      </div>

      {/* Recording Controls */}
      <div className="p-6 border-b border-[hsl(var(--border))] flex flex-col items-center gap-4">
        <button
          onClick={isRecording ? stopRecording : startRecording}
          disabled={status === 'checking' || status === 'unavailable'}
          className={`w-24 h-24 rounded-full flex items-center justify-center transition-all ${
            isRecording
              ? 'bg-red-500 hover:bg-red-600 animate-pulse'
              : 'bg-gradient-to-r from-purple-500 to-pink-500 hover:from-purple-600 hover:to-pink-600'
          } disabled:opacity-50 disabled:cursor-not-allowed`}
        >
          {isRecording ? (
            <MicOff className="w-10 h-10 text-white" />
          ) : (
            <Mic className="w-10 h-10 text-white" />
          )}
        </button>
        <p className="text-sm text-[hsl(var(--muted-foreground))]">
          {isRecording ? 'ã‚¿ãƒƒãƒ—ã—ã¦éŒ²éŸ³åœæ­¢' : 'ã‚¿ãƒƒãƒ—ã—ã¦éŒ²éŸ³é–‹å§‹'}
        </p>
        {isRecording && (
          <div className="w-full max-w-xs space-y-2">
            {/* å›ºå®šãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ */}
            {recordingMode === 'fixed' && (
              <div className="space-y-1">
                <div className="flex items-center justify-between text-xs text-[hsl(var(--muted-foreground))]">
                  <span>éŒ²éŸ³é€²æ—</span>
                  <span className="font-mono">{currentChunkTime}/{fixedDuration}ç§’</span>
                </div>
                <div className="w-full bg-[hsl(var(--secondary))] rounded-full h-2 overflow-hidden">
                  <div
                    className="h-2 rounded-full bg-gradient-to-r from-purple-500 to-pink-500 transition-all duration-1000"
                    style={{ width: `${(currentChunkTime / fixedDuration) * 100}%` }}
                  />
                </div>
              </div>
            )}
            {/* éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒ¡ãƒ¼ã‚¿ãƒ¼ */}
            <div className="flex items-center gap-2">
              <span className="text-xs text-[hsl(var(--muted-foreground))] w-12">éŸ³å£°</span>
              <div className="flex-1 bg-[hsl(var(--secondary))] rounded-full h-3 overflow-hidden">
                <div
                  className={`h-3 rounded-full transition-all duration-75 ${
                    isSpeaking
                      ? 'bg-gradient-to-r from-green-500 to-emerald-400'
                      : 'bg-gradient-to-r from-gray-400 to-gray-500'
                  }`}
                  style={{ width: `${audioLevel}%` }}
                />
              </div>
              <span className={`text-xs w-16 text-right ${isSpeaking ? 'text-green-400' : 'text-[hsl(var(--muted-foreground))]'}`}>
                {isSpeaking ? 'ç™ºè©±ä¸­' : 'ç„¡éŸ³'}
              </span>
            </div>
            {/* èª¬æ˜ */}
            <p className="text-xs text-center text-[hsl(var(--muted-foreground))]">
              {recordingMode === 'fixed'
                ? `${fixedDuration}ç§’ã”ã¨ã«è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã—ã¾ã™`
                : 'ç™ºè©±çµ‚äº†å¾Œã€è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™'
              }
            </p>
          </div>
        )}
      </div>

      {/* Transcripts */}
      <div className="flex-1 overflow-y-auto p-4">
        {transcripts.length === 0 ? (
          <div className="flex flex-col items-center justify-center h-full text-center">
            <Mic className="w-12 h-12 text-[hsl(var(--muted-foreground))] mb-4" />
            <p className="text-[hsl(var(--muted-foreground))]">
              {recordingMode === 'fixed'
                ? `éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã¨ã€${fixedDuration}ç§’ã”ã¨ã«è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã•ã‚Œã¾ã™`
                : 'éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã¨ã€ç™ºè©±ã‚’æ¤œå‡ºã—ã¦è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã•ã‚Œã¾ã™'
              }
            </p>
            {status === 'unavailable' && (
              <div className="mt-4 p-4 bg-red-500/10 border border-red-500/20 rounded-lg text-sm text-red-400 max-w-md">
                <p className="font-medium mb-2">éŸ³å£°APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“</p>
                <ul className="text-left list-disc list-inside space-y-1 text-xs">
                  <li>chrome://flags/#prompt-api-for-gemini-nano-multimodal-input â†’ Enabled</li>
                  <li>Chromeã‚’å†èµ·å‹•</li>
                </ul>
              </div>
            )}
          </div>
        ) : (
          <div className="space-y-3">
            {transcripts.map((transcript) => (
              <div
                key={transcript.id}
                className={`p-4 rounded-lg ${
                  transcript.isProcessing
                    ? 'bg-[hsl(var(--secondary))] animate-pulse'
                    : 'bg-[hsl(var(--card))] border border-[hsl(var(--border))]'
                }`}
              >
                <div className="text-xs text-[hsl(var(--muted-foreground))] mb-2">
                  {transcript.timestamp.toLocaleTimeString('ja-JP')}
                </div>
                {transcript.isProcessing ? (
                  <div className="flex items-center gap-2 text-[hsl(var(--muted-foreground))]">
                    <Loader2 className="w-4 h-4 animate-spin" />
                    <span>æ–‡å­—èµ·ã“ã—ä¸­...</span>
                  </div>
                ) : (
                  <p className="text-[hsl(var(--foreground))]">{transcript.text}</p>
                )}
              </div>
            ))}
            <div ref={transcriptsEndRef} />
          </div>
        )}
      </div>

      {/* Full Transcript */}
      {transcripts.some(t => !t.isProcessing && !t.text.startsWith('ã‚¨ãƒ©ãƒ¼')) && (
        <div className="p-4 border-t border-[hsl(var(--border))] bg-[hsl(var(--card))]">
          <div className="text-xs text-[hsl(var(--muted-foreground))] mb-2">å…¨æ–‡</div>
          <p className="text-sm text-[hsl(var(--foreground))] whitespace-pre-wrap">
            {getFullTranscript()}
          </p>
        </div>
      )}
    </div>
  );
}
