import { useState, useRef, useEffect, useCallback } from 'react';
import { Mic, MicOff, Loader2, AlertCircle, CheckCircle2, Trash2, Languages, FileText, Download, Volume2, Monitor, MonitorSpeaker, RefreshCw } from 'lucide-react';

type Status = 'checking' | 'available' | 'unavailable' | 'recording' | 'downloading';

// éŸ³å£°ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
type AudioSource = 'microphone' | 'system' | 'both';

// æ–‡å­—èµ·ã“ã—çµæœã®çŠ¶æ…‹
type TranscriptionStatus = 'provisional' | 'confirmed' | 're-evaluating';

interface ProcessedChunk {
  id: string;
  timestamp: Date;
  transcription: {
    text: string;
    isProcessing: boolean;
    error?: string;
    status: TranscriptionStatus; // ä»®/ç¢ºå®š/å†è©•ä¾¡ä¸­
  };
  translation: {
    text: string;
    isProcessing: boolean;
    error?: string;
  };
  // æ®µéšçš„å‡¦ç†ç”¨
  audioBlob?: Blob; // å†è©•ä¾¡ç”¨ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
  segmentId?: string; // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚°ãƒ«ãƒ¼ãƒ—IDï¼ˆå†è©•ä¾¡æ™‚ã«çµ±åˆï¼‰
}

interface OverallSummary {
  text: string;
  isProcessing: boolean;
  error?: string;
}

export function VoiceTranscriptionPipeline() {
  const [status, setStatus] = useState<Status>('checking');
  const [error, setError] = useState<string | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [chunks, setChunks] = useState<ProcessedChunk[]>([]);

  // Translatorè¨­å®š
  const [sourceLanguage, setSourceLanguage] = useState('ja');
  const [targetLanguage, setTargetLanguage] = useState('en');

  // Summarizerè¨­å®š
  const [enableSummarization, setEnableSummarization] = useState(true);
  const [summaryType, setSummaryType] = useState<'tldr' | 'key-points' | 'teaser' | 'headline'>('tldr');
  const [summaryFormat, setSummaryFormat] = useState<'plain-text' | 'markdown'>('plain-text');
  const [summaryLength, setSummaryLength] = useState<'short' | 'medium' | 'long'>('medium');

  const [downloadProgress, setDownloadProgress] = useState<{ translator: number; summarizer: number } | null>(null);
  const [transcriptionSummary, setTranscriptionSummary] = useState<OverallSummary>({ text: '', isProcessing: false });
  const [translationSummary, setTranslationSummary] = useState<OverallSummary>({ text: '', isProcessing: false });

  // ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ã®è¦ç´„ç®¡ç†
  interface SummaryCheckpoint {
    summarizedUpTo: number;      // æ—¢ã«è¦ç´„æ¸ˆã¿ã®æ–‡å­—æ•°
    previousSummary: string;     // å‰å›ã®è¦ç´„çµæœ
  }
  const transcriptionCheckpointRef = useRef<SummaryCheckpoint>({ summarizedUpTo: 0, previousSummary: '' });
  const translationCheckpointRef = useRef<SummaryCheckpoint>({ summarizedUpTo: 0, previousSummary: '' });

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const chunksEndRef = useRef<HTMLDivElement>(null);
  const isRecordingRef = useRef(false);
  const mimeTypeRef = useRef<string>('audio/webm');

  // éŸ³å£°è§£æç”¨
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const silenceStartRef = useRef<number | null>(null);
  const hasSpokenRef = useRef(false);

  // éŸ³å£°ãƒ¬ãƒ™ãƒ«å¯è¦–åŒ–ç”¨
  const [audioLevel, setAudioLevel] = useState(0);
  const [isSpeaking, setIsSpeaking] = useState(false);

  // éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰
  const [recordingMode, setRecordingMode] = useState<'vad' | 'fixed'>('vad');
  const [fixedDuration, setFixedDuration] = useState(5); // å›ºå®šéŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
  const [currentChunkTime, setCurrentChunkTime] = useState(0);

  // éŸ³å£°è¨­å®šï¼ˆèª¿æ•´å¯èƒ½ï¼‰
  const [inputGain, setInputGain] = useState(1.0); // ã‚²ã‚¤ãƒ³ï¼ˆ0.1ã€œ3.0ï¼‰
  const [silenceThreshold, setSilenceThreshold] = useState(15); // ç„¡éŸ³é–¾å€¤ï¼ˆ0ã€œ100ï¼‰
  const [silenceDuration, setSilenceDuration] = useState(1500); // ç„¡éŸ³ç¶™ç¶šæ™‚é–“ï¼ˆmsï¼‰

  // GainNodeå‚ç…§
  const gainNodeRef = useRef<GainNode | null>(null);
  const timerRef = useRef<number | null>(null);

  // éŸ³å£°ã‚½ãƒ¼ã‚¹è¨­å®š
  const [audioSource, setAudioSource] = useState<AudioSource>('microphone');
  const systemStreamRef = useRef<MediaStream | null>(null);
  const micStreamRef = useRef<MediaStream | null>(null);
  const mixedStreamRef = useRef<MediaStream | null>(null);

  // æ®µéšçš„æ–‡å­—èµ·ã“ã—è¨­å®š
  const [enableProgressiveTranscription, setEnableProgressiveTranscription] = useState(true);
  const [provisionalInterval, setProvisionalInterval] = useState(3); // ä»®æ–‡å­—èµ·ã“ã—é–“éš”ï¼ˆç§’ï¼‰
  const [reEvaluationInterval, setReEvaluationInterval] = useState(12); // å†è©•ä¾¡é–“éš”ï¼ˆç§’ï¼‰

  // æ®µéšçš„å‡¦ç†ç”¨ã®ãƒãƒƒãƒ•ã‚¡
  const audioBufferRef = useRef<Blob[]>([]); // å†è©•ä¾¡ç”¨éŸ³å£°ãƒãƒƒãƒ•ã‚¡
  const currentSegmentIdRef = useRef<string>(crypto.randomUUID());
  const segmentStartTimeRef = useRef<number>(0);
  const chunkCountInSegmentRef = useRef<number>(0);

  // ä»®å‡¦ç†ã®ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç”¨
  const provisionalAbortControllerRef = useRef<AbortController | null>(null);
  const pendingProvisionalChunksRef = useRef<Set<string>>(new Set()); // å‡¦ç†ä¸­ã®ä»®ãƒãƒ£ãƒ³ã‚¯ID

  // å›ºå®šè¨­å®š
  const MIN_RECORDING_DURATION = 500; // æœ€å°éŒ²éŸ³æ™‚é–“ï¼ˆmsï¼‰

  // APIã®å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯
  const checkAvailability = useCallback(async () => {
    setStatus('checking');
    setError(null);

    // LanguageModel APIãƒã‚§ãƒƒã‚¯
    if (typeof LanguageModel === 'undefined') {
      setStatus('unavailable');
      setError('LanguageModel APIãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
      return;
    }

    // Translator APIãƒã‚§ãƒƒã‚¯
    if (typeof Translator === 'undefined') {
      setStatus('unavailable');
      setError('Translator APIãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
      return;
    }

    // Summarizer APIãƒã‚§ãƒƒã‚¯
    if (typeof Summarizer === 'undefined') {
      setStatus('unavailable');
      setError('Summarizer APIãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
      return;
    }

    try {
      // LanguageModel availability
      const audioAvailability = await LanguageModel.availability({
        expectedInputs: [{ type: 'audio' }],
      });
      console.log('Audio API Availability:', audioAvailability);

      if (audioAvailability !== 'available' && audioAvailability !== 'readily') {
        setStatus('unavailable');
        setError(`éŸ³å£°APIåˆ©ç”¨ä¸å¯: ${audioAvailability}`);
        return;
      }

      // Translator availability - check with default language pair
      const translatorAvailability = await Translator.availability({
        sourceLanguage: 'ja',
        targetLanguage: 'en',
      });
      console.log('Translator API Availability:', translatorAvailability);

      // Summarizer availability
      const summarizerAvailability = await Summarizer.availability();
      console.log('Summarizer API Availability:', summarizerAvailability);

      // ä¸¡æ–¹åˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
      const translatorReady = translatorAvailability === 'readily' || translatorAvailability === 'available';
      const summarizerReady = summarizerAvailability === 'readily' || summarizerAvailability === 'available';
      const translatorDownloadable = translatorAvailability === 'downloadable' || translatorAvailability === 'after-download';
      const summarizerDownloadable = summarizerAvailability === 'downloadable' || summarizerAvailability === 'after-download';

      // ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ãªå ´åˆ
      if (!translatorReady || !summarizerReady) {
        if (!translatorReady && !translatorDownloadable) {
          setStatus('unavailable');
          setError(`ç¿»è¨³APIåˆ©ç”¨ä¸å¯: ${translatorAvailability}`);
          return;
        }
        if (!summarizerReady && !summarizerDownloadable) {
          setStatus('unavailable');
          setError(`è¦ç´„APIåˆ©ç”¨ä¸å¯: ${summarizerAvailability}`);
          return;
        }

        // ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹
        setStatus('downloading');
        setDownloadProgress({ translator: translatorReady ? 100 : 0, summarizer: summarizerReady ? 100 : 0 });

        // Translatorã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if (!translatorReady && translatorDownloadable) {
          console.log('Downloading Translator model...');
          const translatorSession = await Translator.create({
            sourceLanguage: 'ja',
            targetLanguage: 'en',
            monitor(m) {
              m.addEventListener('downloadprogress', (e) => {
                const percent = Math.round((e.loaded / e.total) * 100);
                setDownloadProgress(prev => prev ? { ...prev, translator: percent } : { translator: percent, summarizer: 0 });
              });
            },
          });
          translatorSession.destroy();
          setDownloadProgress(prev => prev ? { ...prev, translator: 100 } : { translator: 100, summarizer: 0 });
        }

        // Summarizerã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if (!summarizerReady && summarizerDownloadable) {
          console.log('Downloading Summarizer model...');
          const summarizerSession = await Summarizer.create({
            monitor(m) {
              m.addEventListener('downloadprogress', (e) => {
                const percent = Math.round((e.loaded / e.total) * 100);
                setDownloadProgress(prev => prev ? { ...prev, summarizer: percent } : { translator: 100, summarizer: percent });
              });
            },
          });
          summarizerSession.destroy();
          setDownloadProgress(prev => prev ? { ...prev, summarizer: 100 } : { translator: 100, summarizer: 100 });
        }

        setDownloadProgress(null);
      }

      setStatus('available');
    } catch (e) {
      setStatus('unavailable');
      setError(e instanceof Error ? e.message : 'Unknown error');
    }
  }, []);

  useEffect(() => {
    checkAvailability();
  }, [checkAvailability]);

  useEffect(() => {
    chunksEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [chunks]);

  // ã‚²ã‚¤ãƒ³å¤‰æ›´æ™‚ã«GainNodeã‚’æ›´æ–°
  useEffect(() => {
    if (gainNodeRef.current) {
      gainNodeRef.current.gain.value = inputGain;
    }
  }, [inputGain]);

  // Blobã‚’ArrayBufferã«å¤‰æ›
  const blobToArrayBuffer = async (blob: Blob): Promise<ArrayBuffer> => {
    return await blob.arrayBuffer();
  };

  // JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰transcriptionã‚’æŠ½å‡ºã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
  const extractTranscription = (response: string): string => {
    console.log('Raw response:', response);

    // å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    const trimmed = response.trim();

    // 1. ã¾ãšé€šå¸¸ã®JSONãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
    try {
      const parsed = JSON.parse(trimmed);
      if (typeof parsed.transcription === 'string') {
        return parsed.transcription;
      }
    } catch {
      // ãƒ‘ãƒ¼ã‚¹å¤±æ•—
    }

    // 2. ä¸å®Œå…¨ãªJSONã®å ´åˆã€é–‰ã˜æ‹¬å¼§ã‚’è¿½åŠ ã—ã¦ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã¿ã‚‹
    if (trimmed.startsWith('{"transcription"') && !trimmed.endsWith('}')) {
      try {
        // æœ«å°¾ã®æ”¹è¡Œã‚„ä¸å®Œå…¨ãªå¼•ç”¨ç¬¦ã‚’å‡¦ç†
        let fixed = trimmed;
        if (!fixed.endsWith('"')) {
          fixed = fixed + '"';
        }
        fixed = fixed + '}';
        const parsed = JSON.parse(fixed);
        if (typeof parsed.transcription === 'string') {
          return parsed.transcription;
        }
      } catch {
        // ãƒ‘ãƒ¼ã‚¹å¤±æ•—
      }
    }

    // 3. "transcription": "..." ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ­£è¦è¡¨ç¾ã§æŠ½å‡º
    const match = trimmed.match(/"transcription"\s*:\s*"((?:[^"\\]|\\.)*)"/);
    if (match && match[1]) {
      // ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚ŒãŸæ–‡å­—ã‚’å‡¦ç†
      return match[1].replace(/\\n/g, '\n').replace(/\\"/g, '"').replace(/\\\\/g, '\\');
    }

    // 4. {"transcription": ã®å¾Œã®æ–‡å­—åˆ—ã‚’ç›´æ¥æŠ½å‡º
    const prefixMatch = trimmed.match(/^\{"transcription"\s*:\s*"(.*)$/s);
    if (prefixMatch && prefixMatch[1]) {
      // æœ«å°¾ã® "}ã‚„æ”¹è¡Œã‚’å‰Šé™¤
      let extracted = prefixMatch[1];
      extracted = extracted.replace(/"\s*\}?\s*$/, '');
      extracted = extracted.replace(/\\n/g, '\n').replace(/\\"/g, '"').replace(/\\\\/g, '\\');
      return extracted;
    }

    // 5. ä½•ã‚‚æŠ½å‡ºã§ããªã„å ´åˆã¯å…ƒã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ï¼ˆJSONãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»ï¼‰
    if (trimmed.startsWith('{"transcription"')) {
      return trimmed.replace(/^\{"transcription"\s*:\s*"?/, '').replace(/"?\s*\}?$/, '');
    }

    return trimmed;
  };

  // è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ï¼‰
  const MAX_NEW_CONTENT_LENGTH = 3000; // æ–°è¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æœ€å¤§é•·

  const summarizeTextWithCheckpoint = useCallback(async (
    fullText: string,
    setSummary: React.Dispatch<React.SetStateAction<OverallSummary>>,
    checkpointRef: React.MutableRefObject<{ summarizedUpTo: number; previousSummary: string }>,
    outputLanguage?: string
  ) => {
    const checkpoint = checkpointRef.current;

    // ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã„å ´åˆã¯ãã®ã¾ã¾è¡¨ç¤º
    if (fullText.trim().length < 50) {
      setSummary({ text: fullText, isProcessing: false });
      return;
    }

    // æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒãªã„å ´åˆã¯å‰å›ã®è¦ç´„ã‚’ç¶­æŒ
    if (fullText.length <= checkpoint.summarizedUpTo && checkpoint.previousSummary) {
      setSummary({ text: checkpoint.previousSummary, isProcessing: false });
      return;
    }

    setSummary(prev => ({ ...prev, isProcessing: true }));

    let summarizerSession: SummarizerSession | null = null;
    try {
      summarizerSession = await Summarizer.create({
        type: summaryType,
        format: summaryFormat,
        length: summaryLength,
        ...(outputLanguage && { outputLanguage }),
      });

      let textToSummarize: string;
      let newCheckpointLength: number;

      // å‰å›ã®è¦ç´„ãŒã‚ã‚‹å ´åˆã¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ã§å‡¦ç†
      if (checkpoint.previousSummary && checkpoint.summarizedUpTo > 0) {
        // æ–°ã—ã„éƒ¨åˆ†ã®ã¿æŠ½å‡º
        const newContent = fullText.slice(checkpoint.summarizedUpTo);

        if (newContent.length > MAX_NEW_CONTENT_LENGTH) {
          // æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚é•·ã™ãã‚‹å ´åˆã¯ã€æœ€æ–°éƒ¨åˆ†ã®ã¿ä½¿ç”¨
          const truncatedNew = newContent.slice(-MAX_NEW_CONTENT_LENGTH);
          textToSummarize = `[ã“ã‚Œã¾ã§ã®è¦ç´„]\n${checkpoint.previousSummary}\n\n[æ–°ã—ã„å†…å®¹]\n...${truncatedNew}`;
          newCheckpointLength = fullText.length;
        } else {
          // å‰å›ã®è¦ç´„ + æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¦ç´„
          textToSummarize = `[ã“ã‚Œã¾ã§ã®è¦ç´„]\n${checkpoint.previousSummary}\n\n[æ–°ã—ã„å†…å®¹]\n${newContent}`;
          newCheckpointLength = fullText.length;
        }

        console.log(`Checkpoint summary: prev=${checkpoint.summarizedUpTo}, new=${newContent.length}, total=${fullText.length}`);
      } else {
        // åˆå›ã¾ãŸã¯å…¨æ–‡ãŒçŸ­ã„å ´åˆ
        if (fullText.length > MAX_NEW_CONTENT_LENGTH) {
          // é•·ã„å ´åˆã¯æœ€æ–°éƒ¨åˆ†ã‚’ä½¿ç”¨
          textToSummarize = '...' + fullText.slice(-MAX_NEW_CONTENT_LENGTH);
        } else {
          textToSummarize = fullText;
        }
        newCheckpointLength = fullText.length;
      }

      const summaryText = await summarizerSession.summarize(textToSummarize);

      // ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’æ›´æ–°
      checkpointRef.current = {
        summarizedUpTo: newCheckpointLength,
        previousSummary: summaryText,
      };

      setSummary({ text: summaryText, isProcessing: false });
    } catch (e) {
      console.error('Summary error:', e);
      const errorMessage = e instanceof Error ? e.message : 'Unknown error';

      if (errorMessage.includes('too large') || errorMessage.includes('too long')) {
        // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å‰å›ã®è¦ç´„ã‚’ç¶­æŒ
        if (checkpoint.previousSummary) {
          setSummary({
            text: checkpoint.previousSummary + '\n\nï¼ˆæ–°ã—ã„å†…å®¹ã¯é•·ã™ãã‚‹ãŸã‚è¿½åŠ ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰',
            isProcessing: false,
          });
        } else {
          setSummary({
            text: 'ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹ãŸã‚è¦ç´„ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸï¼‰',
            isProcessing: false,
          });
        }
      } else {
        setSummary({
          text: checkpoint.previousSummary || '',
          isProcessing: false,
          error: errorMessage,
        });
      }
    } finally {
      if (summarizerSession) summarizerSession.destroy();
    }
  }, [summaryType, summaryFormat, summaryLength]);

  // å…¨æ–‡è¦ç´„ã‚’æ›´æ–°ï¼ˆæ–‡å­—èµ·ã“ã— + ç¿»è¨³ï¼‰- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼
  const updateOverallSummaries = useCallback(async (
    allTranscriptions: string[],
    allTranslations: string[],
    srcLang: string,
    tgtLang: string
  ) => {
    // è¦ç´„ãŒç„¡åŠ¹ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if (!enableSummarization) {
      return;
    }

    // æ–‡å­—èµ·ã“ã—ã®è¦ç´„ï¼ˆã‚½ãƒ¼ã‚¹è¨€èªã§å‡ºåŠ›ï¼‰
    if (allTranscriptions.length > 0) {
      const transcriptionText = allTranscriptions.join('\n\n');
      summarizeTextWithCheckpoint(transcriptionText, setTranscriptionSummary, transcriptionCheckpointRef, srcLang);
    }

    // ç¿»è¨³ã®è¦ç´„ï¼ˆç¿»è¨³å…ˆè¨€èªã§å‡ºåŠ›ï¼‰
    if (allTranslations.length > 0) {
      const translationText = allTranslations.join('\n\n');
      summarizeTextWithCheckpoint(translationText, setTranslationSummary, translationCheckpointRef, tgtLang);
    }
  }, [summarizeTextWithCheckpoint, enableSummarization]);

  // ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—
  const getSystemAudioStream = async (): Promise<MediaStream> => {
    try {
      const stream = await navigator.mediaDevices.getDisplayMedia({
        video: true, // getDisplayMediaã«ã¯video: trueãŒå¿…é ˆ
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
        }
      });

      // ãƒ“ãƒ‡ã‚ªãƒˆãƒ©ãƒƒã‚¯ã¯ä¸è¦ãªã®ã§åœæ­¢
      stream.getVideoTracks().forEach(track => track.stop());

      // éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã®ã¿ã‚’å«ã‚€æ–°ã—ã„ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½œæˆ
      const audioOnlyStream = new MediaStream(stream.getAudioTracks());
      return audioOnlyStream;
    } catch (e) {
      console.error('Failed to get system audio:', e);
      throw new Error('ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”»é¢å…±æœ‰ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚');
    }
  };

  // ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—
  const getMicrophoneStream = async (): Promise<MediaStream> => {
    return await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        sampleRate: 16000,
      }
    });
  };

  // è¤‡æ•°ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’æ··åˆ
  const mixAudioStreams = (streams: MediaStream[]): MediaStream => {
    const audioContext = new AudioContext();
    const destination = audioContext.createMediaStreamDestination();

    streams.forEach(stream => {
      const source = audioContext.createMediaStreamSource(stream);
      source.connect(destination);
    });

    audioContextRef.current = audioContext;
    return destination.stream;
  };

  // éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’è¨­å®š
  const setupAudioStream = async (): Promise<MediaStream> => {
    let finalStream: MediaStream;

    if (audioSource === 'microphone') {
      finalStream = await getMicrophoneStream();
      micStreamRef.current = finalStream;
    } else if (audioSource === 'system') {
      finalStream = await getSystemAudioStream();
      systemStreamRef.current = finalStream;
    } else {
      // ä¸¡æ–¹ã‚’æ··åˆ
      const [micStream, sysStream] = await Promise.all([
        getMicrophoneStream(),
        getSystemAudioStream()
      ]);
      micStreamRef.current = micStream;
      systemStreamRef.current = sysStream;
      finalStream = mixAudioStreams([micStream, sysStream]);
      mixedStreamRef.current = finalStream;
    }

    return finalStream;
  };

  // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å†è©•ä¾¡ã‚’å®Ÿè¡Œ
  const reEvaluateSegment = async (segmentId: string, combinedAudioBlob: Blob) => {
    console.log(`Re-evaluating segment ${segmentId}, size: ${combinedAudioBlob.size}`);

    let languageModelSession: LanguageModelSession | null = null;
    let translatorSession: TranslatorSession | null = null;

    try {
      // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å†è©•ä¾¡ä¸­ã«è¨­å®š
      setChunks(prev =>
        prev.map(c =>
          c.segmentId === segmentId
            ? {
                ...c,
                transcription: { ...c.transcription, status: 're-evaluating' as TranscriptionStatus }
              }
            : c
        )
      );

      // æ–‡å­—èµ·ã“ã—ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
      languageModelSession = await LanguageModel.create({
        expectedInputs: [{ type: 'audio' }],
        expectedOutputLanguages: [sourceLanguage],
        systemPrompt: 'éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ã€transcriptionãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«çµæœã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚éŸ³å£°ãŒèãå–ã‚Œãªã„å ´åˆã¯ç©ºæ–‡å­—ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚å‰å¾Œã®æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦ã€è‡ªç„¶ãªæ—¥æœ¬èªã«ãªã‚‹ã‚ˆã†ã«æ–‡å­—èµ·ã“ã—ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚',
      });

      const arrayBuffer = await blobToArrayBuffer(combinedAudioBlob);

      const transcriptionSchema = {
        type: 'object',
        properties: {
          transcription: { type: 'string', description: 'éŸ³å£°ã®æ–‡å­—èµ·ã“ã—çµæœ' },
        },
        required: ['transcription'],
        additionalProperties: false,
      };

      const rawResponse = await languageModelSession.prompt(
        [
          {
            role: 'user',
            content: [
              { type: 'text', value: 'ã“ã®éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦è‡ªç„¶ãªæ–‡ç« ã«ã—ã¦ãã ã•ã„ï¼š' },
              { type: 'audio', value: arrayBuffer },
            ],
          },
        ],
        { responseConstraint: transcriptionSchema }
      );

      const transcription = extractTranscription(rawResponse);
      console.log(`Re-evaluated transcription for segment ${segmentId}:`, transcription);

      // ç¿»è¨³
      translatorSession = await Translator.create({
        sourceLanguage: sourceLanguage,
        targetLanguage: targetLanguage,
      });

      const translatedText = await translatorSession.translate(transcription);

      // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ã®ãƒãƒ£ãƒ³ã‚¯ã‚’çµ±åˆã—ã¦æ›´æ–°
      setChunks(prev => {
        const segmentChunks = prev.filter(c => c.segmentId === segmentId);
        const otherChunks = prev.filter(c => c.segmentId !== segmentId);

        if (segmentChunks.length === 0) return prev;

        // æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã«çµ±åˆçµæœã‚’è¨­å®šã€ä»–ã¯å‰Šé™¤
        const firstChunk = segmentChunks[0];
        const consolidatedChunk: ProcessedChunk = {
          ...firstChunk,
          transcription: {
            text: transcription,
            isProcessing: false,
            status: 'confirmed' as TranscriptionStatus,
          },
          translation: {
            text: translatedText,
            isProcessing: false,
          },
        };

        const updated = [...otherChunks, consolidatedChunk].sort(
          (a, b) => a.timestamp.getTime() - b.timestamp.getTime()
        );

        // è¦ç´„ã‚’æ›´æ–°
        const allTranscriptions = updated
          .filter(c => c.transcription.text && !c.transcription.error)
          .map(c => c.transcription.text);

        const allTranslations = updated
          .filter(c => c.translation.text && !c.translation.error)
          .map(c => c.translation.text);

        updateOverallSummaries(allTranscriptions, allTranslations, sourceLanguage, targetLanguage);

        return updated;
      });
    } catch (e) {
      console.error('Re-evaluation error:', e);
      // ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä»®çµæœã‚’ç¢ºå®šçµæœã«å¤‰æ›´
      setChunks(prev =>
        prev.map(c =>
          c.segmentId === segmentId
            ? {
                ...c,
                transcription: { ...c.transcription, status: 'confirmed' as TranscriptionStatus }
              }
            : c
        )
      );
    } finally {
      if (languageModelSession) languageModelSession.destroy();
      if (translatorSession) translatorSession.destroy();
    }
  };

  // éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ï¼ˆæ–‡å­—èµ·ã“ã—â†’ç¿»è¨³ï¼‰
  const processChunk = async (
    audioBlob: Blob,
    isProvisional: boolean = false,
    segmentId?: string,
    abortSignal?: AbortSignal
  ) => {
    if (audioBlob.size < 1000) {
      console.log('Audio chunk too small, skipping:', audioBlob.size);
      return;
    }

    const chunkId = crypto.randomUUID();

    // ä»®å‡¦ç†ã®å ´åˆã¯pendingã«è¿½åŠ 
    if (isProvisional) {
      pendingProvisionalChunksRef.current.add(chunkId);
    }

    const newChunk: ProcessedChunk = {
      id: chunkId,
      timestamp: new Date(),
      transcription: {
        text: '',
        isProcessing: true,
        status: isProvisional ? 'provisional' : 'confirmed'
      },
      translation: { text: '', isProcessing: false },
      audioBlob: isProvisional ? audioBlob : undefined,
      segmentId: segmentId,
    };

    setChunks(prev => [...prev, newChunk]);

    let languageModelSession: LanguageModelSession | null = null;
    let translatorSession: TranslatorSession | null = null;

    // ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒã‚§ãƒƒã‚¯ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼
    const checkAborted = () => {
      if (abortSignal?.aborted) {
        throw new Error('ABORTED');
      }
    };

    try {
      checkAborted();

      // ã‚¹ãƒ†ãƒƒãƒ—1: æ–‡å­—èµ·ã“ã—ï¼ˆæ§‹é€ åŒ–ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆï¼‰
      languageModelSession = await LanguageModel.create({
        expectedInputs: [{ type: 'audio' }],
        expectedOutputLanguages: [sourceLanguage],
        systemPrompt: 'éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ã€transcriptionãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«çµæœã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚éŸ³å£°ãŒèãå–ã‚Œãªã„å ´åˆã¯ç©ºæ–‡å­—ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚',
      });

      checkAborted();

      const arrayBuffer = await blobToArrayBuffer(audioBlob);
      console.log('Audio buffer size:', arrayBuffer.byteLength);

      checkAborted();

      // æ§‹é€ åŒ–ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆç”¨ã®JSON Schema
      const transcriptionSchema = {
        type: 'object',
        properties: {
          transcription: { type: 'string', description: 'éŸ³å£°ã®æ–‡å­—èµ·ã“ã—çµæœ' },
        },
        required: ['transcription'],
        additionalProperties: false,
      };

      const rawResponse = await languageModelSession.prompt(
        [
          {
            role: 'user',
            content: [
              { type: 'text', value: 'ã“ã®éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ï¼š' },
              { type: 'audio', value: arrayBuffer },
            ],
          },
        ],
        { responseConstraint: transcriptionSchema }
      );

      checkAborted();

      // JSONã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
      const transcription = extractTranscription(rawResponse);
      console.log('Extracted transcription:', transcription);

      setChunks(prev =>
        prev.map(c =>
          c.id === chunkId
            ? {
                ...c,
                transcription: {
                  text: transcription,
                  isProcessing: false,
                  status: isProvisional ? 'provisional' : 'confirmed'
                },
                translation: { text: '', isProcessing: true },
              }
            : c
        )
      );

      checkAborted();

      // ã‚¹ãƒ†ãƒƒãƒ—2: ç¿»è¨³
      translatorSession = await Translator.create({
        sourceLanguage: sourceLanguage,
        targetLanguage: targetLanguage,
      });

      checkAborted();

      const translatedText = await translatorSession.translate(transcription);

      checkAborted();

      // ãƒãƒ£ãƒ³ã‚¯ã‚’æ›´æ–°
      setChunks(prev => {
        const updated = prev.map(c =>
          c.id === chunkId
            ? {
                ...c,
                translation: { text: translatedText, isProcessing: false },
              }
            : c
        );

        // å…¨ãƒ†ã‚­ã‚¹ãƒˆã‚’åé›†ã—ã¦è¦ç´„ã‚’æ›´æ–°
        const allTranscriptions = updated
          .filter(c => c.transcription.text && !c.transcription.error)
          .map(c => c.transcription.text);

        const allTranslations = updated
          .filter(c => c.translation.text && !c.translation.error)
          .map(c => c.translation.text);

        // éåŒæœŸã§è¦ç´„ã‚’æ›´æ–°
        updateOverallSummaries(allTranscriptions, allTranslations, sourceLanguage, targetLanguage);

        return updated;
      });
    } catch (e) {
      const errorMessage = e instanceof Error ? e.message : 'Unknown error';

      // ABORTED ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯é™ã‹ã«å‡¦ç†ä¸­ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤
      if (errorMessage === 'ABORTED') {
        console.log(`Provisional processing aborted for chunk ${chunkId}`);
        setChunks(prev => prev.filter(c => c.id !== chunkId));
        return;
      }

      console.error('Processing error:', e);

      setChunks(prev =>
        prev.map(c =>
          c.id === chunkId
            ? {
                ...c,
                transcription: c.transcription.isProcessing
                  ? { text: '', isProcessing: false, error: errorMessage, status: 'confirmed' as TranscriptionStatus }
                  : c.transcription,
                translation: c.translation.isProcessing
                  ? { text: '', isProcessing: false, error: errorMessage }
                  : c.translation,
              }
            : c
        )
      );
    } finally {
      // pendingã‹ã‚‰å‰Šé™¤
      if (isProvisional) {
        pendingProvisionalChunksRef.current.delete(chunkId);
      }
      if (languageModelSession) languageModelSession.destroy();
      if (translatorSession) translatorSession.destroy();
    }
  };

  // éŒ²éŸ³é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²
  const recordingStartTimeRef = useRef<number>(0);

  // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ç›£è¦–
  const startAudioAnalysis = () => {
    if (!analyserRef.current) return;

    const analyser = analyserRef.current;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    const analyze = () => {
      if (!isRecordingRef.current) return;

      analyser.getByteFrequencyData(dataArray);

      // å¹³å‡éŸ³é‡ã‚’è¨ˆç®—
      const average = dataArray.reduce((a, b) => a + b, 0) / bufferLength;
      setAudioLevel(Math.min(100, (average / 128) * 100));

      // VADãƒ¢ãƒ¼ãƒ‰ã®ã¿ç„¡éŸ³æ¤œå‡ºã‚’è¡Œã†
      if (recordingMode === 'vad') {
        const now = Date.now();
        const recordingDuration = now - recordingStartTimeRef.current;

        if (average > silenceThreshold) {
          // éŸ³å£°æ¤œå‡º
          setIsSpeaking(true);
          hasSpokenRef.current = true;
          silenceStartRef.current = null;
        } else {
          // ç„¡éŸ³
          setIsSpeaking(false);

          if (hasSpokenRef.current && recordingDuration > MIN_RECORDING_DURATION) {
            // ç™ºè©±å¾Œã®ç„¡éŸ³ã‚’æ¤œå‡º
            if (silenceStartRef.current === null) {
              silenceStartRef.current = now;
            } else if (now - silenceStartRef.current > silenceDuration) {
              // ç„¡éŸ³ãŒä¸€å®šæ™‚é–“ç¶šã„ãŸã‚‰éŒ²éŸ³åœæ­¢
              console.log('Silence detected, stopping current recording');
              if (mediaRecorderRef.current?.state === 'recording') {
                mediaRecorderRef.current.stop();
              }
              return; // æ¬¡ã®analyzeã¯å‘¼ã°ãªã„
            }
          }
        }
      } else {
        // å›ºå®šãƒ¢ãƒ¼ãƒ‰ã§ã¯éŸ³å£°ãƒ¬ãƒ™ãƒ«ã®ã¿è¡¨ç¤º
        setIsSpeaking(average > silenceThreshold);
      }

      animationFrameRef.current = requestAnimationFrame(analyze);
    };

    analyze();
  };

  // å†è©•ä¾¡ã‚¿ã‚¤ãƒãƒ¼
  const reEvaluationTimerRef = useRef<number | null>(null);

  // ä»®å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¦å†è©•ä¾¡ã‚’å®Ÿè¡Œ
  const triggerReEvaluation = () => {
    const segmentId = currentSegmentIdRef.current;
    const audioChunks = [...audioBufferRef.current];

    if (audioChunks.length === 0) {
      console.log('No audio chunks for re-evaluation');
      return;
    }

    console.log(`Triggering re-evaluation for segment ${segmentId}, ${audioChunks.length} chunks`);

    // ä»®å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    if (provisionalAbortControllerRef.current) {
      provisionalAbortControllerRef.current.abort();
      provisionalAbortControllerRef.current = null;
    }

    // å‡¦ç†ä¸­ã®ä»®ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤
    setChunks(prev => prev.filter(c =>
      c.segmentId !== segmentId || c.transcription.status === 'confirmed'
    ));

    // éŸ³å£°ã‚’çµåˆ
    const combinedBlob = new Blob(audioChunks, { type: mimeTypeRef.current });

    // ãƒãƒƒãƒ•ã‚¡ã‚’ãƒªã‚»ãƒƒãƒˆ
    audioBufferRef.current = [];
    chunkCountInSegmentRef.current = 0;

    // æ–°ã—ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆIDã‚’ç”Ÿæˆ
    currentSegmentIdRef.current = crypto.randomUUID();
    segmentStartTimeRef.current = Date.now();

    // æ–°ã—ã„AbortControllerã‚’ä½œæˆ
    provisionalAbortControllerRef.current = new AbortController();

    // å†è©•ä¾¡ã‚’å®Ÿè¡Œï¼ˆç¢ºå®šçµæœã¨ã—ã¦ï¼‰
    reEvaluateSegment(segmentId, combinedBlob);
  };

  // æ–°ã—ã„MediaRecorderã‚’ä½œæˆ
  const startNewRecorder = () => {
    if (!streamRef.current || !isRecordingRef.current) return;

    chunksRef.current = [];
    hasSpokenRef.current = false;
    silenceStartRef.current = null;
    recordingStartTimeRef.current = Date.now();
    setCurrentChunkTime(0);

    const mediaRecorder = new MediaRecorder(streamRef.current, {
      mimeType: mimeTypeRef.current
    });
    mediaRecorderRef.current = mediaRecorder;

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        chunksRef.current.push(event.data);
        // æ®µéšçš„å‡¦ç†ç”¨ãƒãƒƒãƒ•ã‚¡ã«ã‚‚è¿½åŠ 
        if (enableProgressiveTranscription) {
          audioBufferRef.current.push(event.data);
        }
      }
    };

    mediaRecorder.onstop = () => {
      // VADãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ç™ºè©±ãŒã‚ã£ãŸå ´åˆã®ã¿å‡¦ç†ã€å›ºå®šãƒ¢ãƒ¼ãƒ‰ã¯å¸¸ã«å‡¦ç†
      const shouldProcess = recordingMode === 'fixed' || hasSpokenRef.current;

      if (chunksRef.current.length > 0 && shouldProcess) {
        const audioBlob = new Blob(chunksRef.current, { type: mimeTypeRef.current });
        console.log('Processing audio chunk:', audioBlob.size, 'bytes');

        if (audioBlob.size >= 1000) {
          if (enableProgressiveTranscription) {
            // æ®µéšçš„å‡¦ç†: ä»®æ–‡å­—èµ·ã“ã—
            const segmentId = currentSegmentIdRef.current;
            chunkCountInSegmentRef.current++;

            // AbortControllerãŒãªã‘ã‚Œã°ä½œæˆ
            if (!provisionalAbortControllerRef.current) {
              provisionalAbortControllerRef.current = new AbortController();
            }

            processChunk(
              audioBlob,
              true, // isProvisional
              segmentId,
              provisionalAbortControllerRef.current.signal
            );

            // å†è©•ä¾¡ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
            const elapsedSinceSegmentStart = (Date.now() - segmentStartTimeRef.current) / 1000;
            if (elapsedSinceSegmentStart >= reEvaluationInterval) {
              triggerReEvaluation();
            }
          } else {
            // é€šå¸¸å‡¦ç†
            processChunk(audioBlob);
          }
        } else {
          console.log('Audio chunk too small, skipping');
        }
      }

      // éŒ²éŸ³ç¶™ç¶šä¸­ãªã‚‰æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é–‹å§‹
      if (isRecordingRef.current) {
        startNewRecorder();
      }
    };

    // 100msã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    mediaRecorder.start(100);

    if (recordingMode === 'vad') {
      // éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰
      console.log('Started new recorder (voice-activated)');
      startAudioAnalysis();
    } else {
      // å›ºå®šæ™‚é–“ãƒ¢ãƒ¼ãƒ‰ - æ®µéšçš„å‡¦ç†ã®å ´åˆã¯çŸ­ã„é–“éš”ã§
      const interval = enableProgressiveTranscription ? provisionalInterval : fixedDuration;
      console.log(`Started new recorder (fixed ${interval}s, progressive: ${enableProgressiveTranscription})`);
      hasSpokenRef.current = true; // å›ºå®šãƒ¢ãƒ¼ãƒ‰ã§ã¯å¸¸ã«trueã«ã™ã‚‹

      // ã‚¿ã‚¤ãƒãƒ¼ã§ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ã¨è‡ªå‹•åœæ­¢
      let count = 0;
      if (timerRef.current) {
        window.clearInterval(timerRef.current);
      }
      timerRef.current = window.setInterval(() => {
        count++;
        setCurrentChunkTime(count);

        if (count >= interval) {
          if (timerRef.current) {
            window.clearInterval(timerRef.current);
            timerRef.current = null;
          }
          if (mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
          }
        }
      }, 1000);

      // éŸ³å£°ãƒ¬ãƒ™ãƒ«è¡¨ç¤ºã®ã¿ï¼ˆVADãªã—ï¼‰
      startAudioAnalysis();
    }
  };

  // éŒ²éŸ³é–‹å§‹
  const startRecording = async () => {
    try {
      // éŸ³å£°ã‚½ãƒ¼ã‚¹ã‚’è¨­å®š
      const stream = await setupAudioStream();
      streamRef.current = stream;

      // AudioContextãŒæ—¢ã«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼ˆmixAudioStreamsã§ä½œæˆï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
      if (!audioContextRef.current) {
        audioContextRef.current = new AudioContext();
      }

      // AnalyserNodeã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
      if (!analyserRef.current) {
        analyserRef.current = audioContextRef.current.createAnalyser();
        analyserRef.current.fftSize = 256;
        analyserRef.current.smoothingTimeConstant = 0.8;
      }

      // GainNodeã‚’ä½œæˆã—ã¦ã‚²ã‚¤ãƒ³ã‚’é©ç”¨
      if (!gainNodeRef.current) {
        gainNodeRef.current = audioContextRef.current.createGain();
        gainNodeRef.current.gain.value = inputGain;

        const source = audioContextRef.current.createMediaStreamSource(stream);
        source.connect(gainNodeRef.current);
        gainNodeRef.current.connect(analyserRef.current);
      }

      mimeTypeRef.current = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : MediaRecorder.isTypeSupported('audio/webm')
          ? 'audio/webm'
          : 'audio/mp4';

      console.log('Using MIME type:', mimeTypeRef.current);
      console.log('Audio source:', audioSource);

      // æ®µéšçš„å‡¦ç†ã®åˆæœŸåŒ–
      if (enableProgressiveTranscription) {
        audioBufferRef.current = [];
        currentSegmentIdRef.current = crypto.randomUUID();
        segmentStartTimeRef.current = Date.now();
        chunkCountInSegmentRef.current = 0;
        provisionalAbortControllerRef.current = new AbortController();
        pendingProvisionalChunksRef.current.clear();
      }

      setIsRecording(true);
      isRecordingRef.current = true;
      setStatus('recording');

      startNewRecorder();
    } catch (e) {
      console.error('Recording error:', e);
      setError(e instanceof Error ? e.message : 'éŸ³å£°å…¥åŠ›ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“');
    }
  };

  // éŒ²éŸ³åœæ­¢
  const stopRecording = () => {
    isRecordingRef.current = false;

    // ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    if (timerRef.current) {
      window.clearInterval(timerRef.current);
      timerRef.current = null;
    }

    // å†è©•ä¾¡ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    if (reEvaluationTimerRef.current) {
      window.clearInterval(reEvaluationTimerRef.current);
      reEvaluationTimerRef.current = null;
    }

    // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }

    // æ®‹ã£ã¦ã„ã‚‹ãƒãƒƒãƒ•ã‚¡ãŒã‚ã‚Œã°æœ€çµ‚çš„ãªå†è©•ä¾¡ã‚’å®Ÿè¡Œ
    if (enableProgressiveTranscription && audioBufferRef.current.length > 0) {
      triggerReEvaluation();
    }

    // ä»®å‡¦ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    if (provisionalAbortControllerRef.current) {
      provisionalAbortControllerRef.current.abort();
      provisionalAbortControllerRef.current = null;
    }

    // AudioContextã‚’ã‚¯ãƒ­ãƒ¼ã‚º
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    // å…¨ã¦ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    if (micStreamRef.current) {
      micStreamRef.current.getTracks().forEach(track => track.stop());
      micStreamRef.current = null;
    }
    if (systemStreamRef.current) {
      systemStreamRef.current.getTracks().forEach(track => track.stop());
      systemStreamRef.current = null;
    }
    if (mixedStreamRef.current) {
      mixedStreamRef.current.getTracks().forEach(track => track.stop());
      mixedStreamRef.current = null;
    }

    // AnalyserNodeã¨GainNodeã‚’ãƒªã‚»ãƒƒãƒˆ
    analyserRef.current = null;
    gainNodeRef.current = null;

    setIsRecording(false);
    setIsSpeaking(false);
    setAudioLevel(0);
    setCurrentChunkTime(0);
    setStatus('available');
  };

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      isRecordingRef.current = false;
      if (timerRef.current) {
        window.clearInterval(timerRef.current);
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  const clearChunks = () => {
    setChunks([]);
    setTranscriptionSummary({ text: '', isProcessing: false });
    setTranslationSummary({ text: '', isProcessing: false });
    // ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚‚ãƒªã‚»ãƒƒãƒˆ
    transcriptionCheckpointRef.current = { summarizedUpTo: 0, previousSummary: '' };
    translationCheckpointRef.current = { summarizedUpTo: 0, previousSummary: '' };
  };

  return (
    <div className="flex flex-col h-full">
      {/* Header */}
      <div className="flex items-center justify-between p-4 border-b border-[hsl(var(--border))]">
        <h1 className="text-lg font-semibold">éŸ³å£°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆæ–‡å­—èµ·ã“ã—â†’ç¿»è¨³â†’è¦ç´„ï¼‰</h1>
        <div className="flex items-center gap-3">
          <div className={`flex items-center gap-2 px-3 py-1.5 rounded-full text-xs ${
            status === 'checking' ? 'bg-yellow-500/20 text-yellow-400' :
            status === 'downloading' ? 'bg-blue-500/20 text-blue-400' :
            status === 'available' ? 'bg-green-500/20 text-green-400' :
            status === 'recording' ? 'bg-red-500/20 text-red-400' :
            'bg-red-500/20 text-red-400'
          }`}>
            {status === 'checking' && <Loader2 className="w-4 h-4 animate-spin" />}
            {status === 'downloading' && <Download className="w-4 h-4 animate-bounce" />}
            {status === 'available' && <CheckCircle2 className="w-4 h-4" />}
            {status === 'recording' && <Mic className="w-4 h-4 animate-pulse" />}
            {status === 'unavailable' && <AlertCircle className="w-4 h-4" />}
            <span>
              {status === 'checking' && 'ç¢ºèªä¸­...'}
              {status === 'downloading' && (
                downloadProgress
                  ? `ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­... ç¿»è¨³:${downloadProgress.translator}% è¦ç´„:${downloadProgress.summarizer}%`
                  : 'ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...'
              )}
              {status === 'available' && 'æº–å‚™å®Œäº†'}
              {status === 'recording' && (
                recordingMode === 'vad'
                  ? (isSpeaking ? 'ğŸ¤ ç™ºè©±æ¤œå‡ºä¸­...' : 'ğŸ”‡ å¾…æ©Ÿä¸­...')
                  : enableProgressiveTranscription
                    ? `â±ï¸ éŒ²éŸ³ä¸­ (${currentChunkTime}s / ${provisionalInterval}s) [æ®µéšçš„å‡¦ç†]`
                    : `â±ï¸ éŒ²éŸ³ä¸­ (${currentChunkTime}s / ${fixedDuration}s)`
              )}
              {status === 'unavailable' && (error || 'APIåˆ©ç”¨ä¸å¯')}
            </span>
          </div>
          {chunks.length > 0 && (
            <button
              onClick={clearChunks}
              className="text-xs text-[hsl(var(--muted-foreground))] hover:text-[hsl(var(--foreground))] transition-colors flex items-center gap-1"
            >
              <Trash2 className="w-3 h-3" />
              ã‚¯ãƒªã‚¢
            </button>
          )}
        </div>
      </div>

      {/* Settings */}
      <div className="p-4 border-b border-[hsl(var(--border))] bg-[hsl(var(--secondary)/0.3)]">
        <div className="grid grid-cols-2 gap-4">
          {/* ç¿»è¨³è¨­å®š */}
          <div className="space-y-2">
            <h3 className="text-xs font-medium text-[hsl(var(--muted-foreground))] flex items-center gap-1">
              <Languages className="w-3 h-3" />
              ç¿»è¨³è¨­å®š
            </h3>
            <div className="flex items-center gap-2">
              <select
                value={sourceLanguage}
                onChange={(e) => setSourceLanguage(e.target.value)}
                disabled={isRecording}
                className="flex-1 px-2 py-1 rounded-md border border-[hsl(var(--border))] bg-[hsl(var(--background))] text-[hsl(var(--foreground))] text-xs disabled:opacity-50"
              >
                <option value="ja">æ—¥æœ¬èª</option>
                <option value="en">è‹±èª</option>
                <option value="zh">ä¸­å›½èª</option>
                <option value="ko">éŸ“å›½èª</option>
                <option value="es">ã‚¹ãƒšã‚¤ãƒ³èª</option>
                <option value="fr">ãƒ•ãƒ©ãƒ³ã‚¹èª</option>
                <option value="de">ãƒ‰ã‚¤ãƒ„èª</option>
              </select>
              <span className="text-xs text-[hsl(var(--muted-foreground))]">â†’</span>
              <select
                value={targetLanguage}
                onChange={(e) => setTargetLanguage(e.target.value)}
                disabled={isRecording}
                className="flex-1 px-2 py-1 rounded-md border border-[hsl(var(--border))] bg-[hsl(var(--background))] text-[hsl(var(--foreground))] text-xs disabled:opacity-50"
              >
                <option value="en">è‹±èª</option>
                <option value="ja">æ—¥æœ¬èª</option>
                <option value="zh">ä¸­å›½èª</option>
                <option value="ko">éŸ“å›½èª</option>
                <option value="es">ã‚¹ãƒšã‚¤ãƒ³èª</option>
                <option value="fr">ãƒ•ãƒ©ãƒ³ã‚¹èª</option>
                <option value="de">ãƒ‰ã‚¤ãƒ„èª</option>
              </select>
            </div>
          </div>

          {/* è¦ç´„è¨­å®š */}
          <div className="space-y-2">
            <div className="flex items-center justify-between">
              <h3 className="text-xs font-medium text-[hsl(var(--muted-foreground))] flex items-center gap-1">
                <FileText className="w-3 h-3" />
                è¦ç´„è¨­å®š
              </h3>
              <button
                onClick={() => setEnableSummarization(!enableSummarization)}
                disabled={isRecording}
                className={`px-2 py-0.5 rounded text-xs transition-colors ${
                  enableSummarization
                    ? 'bg-green-500/20 text-green-400 hover:bg-green-500/30'
                    : 'bg-gray-500/20 text-gray-400 hover:bg-gray-500/30'
                } disabled:opacity-50`}
              >
                {enableSummarization ? 'ON' : 'OFF'}
              </button>
            </div>
            {enableSummarization && (
              <div className="flex items-center gap-2">
                <select
                  value={summaryType}
                  onChange={(e) => setSummaryType(e.target.value as 'tldr' | 'key-points' | 'teaser' | 'headline')}
                  disabled={isRecording}
                  className="flex-1 px-2 py-1 rounded-md border border-[hsl(var(--border))] bg-[hsl(var(--background))] text-[hsl(var(--foreground))] text-xs disabled:opacity-50"
                >
                  <option value="tldr">TL;DR</option>
                  <option value="key-points">ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ</option>
                  <option value="teaser">ãƒ†ã‚£ãƒ¼ã‚¶ãƒ¼</option>
                  <option value="headline">è¦‹å‡ºã—</option>
                </select>
                <select
                  value={summaryFormat}
                  onChange={(e) => setSummaryFormat(e.target.value as 'plain-text' | 'markdown')}
                  disabled={isRecording}
                  className="flex-1 px-2 py-1 rounded-md border border-[hsl(var(--border))] bg-[hsl(var(--background))] text-[hsl(var(--foreground))] text-xs disabled:opacity-50"
                >
                  <option value="plain-text">ãƒ—ãƒ¬ãƒ¼ãƒ³</option>
                  <option value="markdown">Markdown</option>
                </select>
                <select
                  value={summaryLength}
                  onChange={(e) => setSummaryLength(e.target.value as 'short' | 'medium' | 'long')}
                  disabled={isRecording}
                  className="flex-1 px-2 py-1 rounded-md border border-[hsl(var(--border))] bg-[hsl(var(--background))] text-[hsl(var(--foreground))] text-xs disabled:opacity-50"
                >
                  <option value="short">çŸ­ã„</option>
                  <option value="medium">ä¸­ç¨‹åº¦</option>
                  <option value="long">é•·ã„</option>
                </select>
              </div>
            )}
          </div>
        </div>

        {/* éŸ³å£°ã‚½ãƒ¼ã‚¹è¨­å®š */}
        <div className="mt-4 pt-4 border-t border-[hsl(var(--border))]">
          <h3 className="text-xs font-medium text-[hsl(var(--muted-foreground))] flex items-center gap-1 mb-3">
            <MonitorSpeaker className="w-3 h-3" />
            éŸ³å£°ã‚½ãƒ¼ã‚¹
          </h3>
          <div className="flex items-center gap-2">
            <button
              onClick={() => setAudioSource('microphone')}
              disabled={isRecording}
              className={`flex items-center gap-1.5 px-3 py-1.5 rounded-md text-xs transition-colors ${
                audioSource === 'microphone'
                  ? 'bg-purple-500 text-white'
                  : 'bg-[hsl(var(--secondary))] text-[hsl(var(--foreground))] hover:bg-[hsl(var(--secondary)/0.8)]'
              } disabled:opacity-50`}
            >
              <Mic className="w-3 h-3" />
              ãƒã‚¤ã‚¯
            </button>
            <button
              onClick={() => setAudioSource('system')}
              disabled={isRecording}
              className={`flex items-center gap-1.5 px-3 py-1.5 rounded-md text-xs transition-colors ${
                audioSource === 'system'
                  ? 'bg-purple-500 text-white'
                  : 'bg-[hsl(var(--secondary))] text-[hsl(var(--foreground))] hover:bg-[hsl(var(--secondary)/0.8)]'
              } disabled:opacity-50`}
            >
              <Monitor className="w-3 h-3" />
              ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°
            </button>
            <button
              onClick={() => setAudioSource('both')}
              disabled={isRecording}
              className={`flex items-center gap-1.5 px-3 py-1.5 rounded-md text-xs transition-colors ${
                audioSource === 'both'
                  ? 'bg-purple-500 text-white'
                  : 'bg-[hsl(var(--secondary))] text-[hsl(var(--foreground))] hover:bg-[hsl(var(--secondary)/0.8)]'
              } disabled:opacity-50`}
            >
              <MonitorSpeaker className="w-3 h-3" />
              ä¸¡æ–¹
            </button>
          </div>
          {audioSource !== 'microphone' && (
            <p className="text-xs text-[hsl(var(--muted-foreground))] mt-2">
              âš ï¸ ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€éŒ²éŸ³é–‹å§‹æ™‚ã«ç”»é¢å…±æœ‰ã‚’è¨±å¯ã—ã¦ãã ã•ã„
            </p>
          )}
        </div>

        {/* æ®µéšçš„å‡¦ç†è¨­å®š */}
        <div className="mt-4 pt-4 border-t border-[hsl(var(--border))]">
          <div className="flex items-center justify-between mb-3">
            <h3 className="text-xs font-medium text-[hsl(var(--muted-foreground))] flex items-center gap-1">
              <RefreshCw className="w-3 h-3" />
              æ®µéšçš„å‡¦ç†ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç²¾åº¦å‘ä¸Šï¼‰
            </h3>
            <button
              onClick={() => setEnableProgressiveTranscription(!enableProgressiveTranscription)}
              disabled={isRecording}
              className={`px-2 py-0.5 rounded text-xs transition-colors ${
                enableProgressiveTranscription
                  ? 'bg-green-500/20 text-green-400 hover:bg-green-500/30'
                  : 'bg-gray-500/20 text-gray-400 hover:bg-gray-500/30'
              } disabled:opacity-50`}
            >
              {enableProgressiveTranscription ? 'ON' : 'OFF'}
            </button>
          </div>
          {enableProgressiveTranscription && (
            <div className="grid grid-cols-2 gap-4">
              <div className="space-y-1">
                <div className="flex justify-between items-center">
                  <label className="text-xs text-[hsl(var(--muted-foreground))]">ä»®æ–‡å­—èµ·ã“ã—é–“éš”</label>
                  <span className="text-xs font-mono text-[hsl(var(--foreground))]">{provisionalInterval}ç§’</span>
                </div>
                <input
                  type="range"
                  min="2"
                  max="10"
                  step="1"
                  value={provisionalInterval}
                  onChange={(e) => setProvisionalInterval(parseInt(e.target.value))}
                  disabled={isRecording}
                  className="w-full h-2 bg-[hsl(var(--secondary))] rounded-lg appearance-none cursor-pointer accent-purple-500 disabled:opacity-50"
                />
                <div className="flex justify-between text-[10px] text-[hsl(var(--muted-foreground))]">
                  <span>2ç§’</span>
                  <span>10ç§’</span>
                </div>
              </div>
              <div className="space-y-1">
                <div className="flex justify-between items-center">
                  <label className="text-xs text-[hsl(var(--muted-foreground))]">å†è©•ä¾¡é–“éš”</label>
                  <span className="text-xs font-mono text-[hsl(var(--foreground))]">{reEvaluationInterval}ç§’</span>
                </div>
                <input
                  type="range"
                  min="6"
                  max="30"
                  step="3"
                  value={reEvaluationInterval}
                  onChange={(e) => setReEvaluationInterval(parseInt(e.target.value))}
                  disabled={isRecording}
                  className="w-full h-2 bg-[hsl(var(--secondary))] rounded-lg appearance-none cursor-pointer accent-purple-500 disabled:opacity-50"
                />
                <div className="flex justify-between text-[10px] text-[hsl(var(--muted-foreground))]">
                  <span>6ç§’</span>
                  <span>30ç§’</span>
                </div>
              </div>
            </div>
          )}
          {enableProgressiveTranscription && (
            <p className="text-xs text-[hsl(var(--muted-foreground))] mt-2">
              ğŸ’¡ {provisionalInterval}ç§’ã”ã¨ã«ä»®æ–‡å­—èµ·ã“ã— â†’ {reEvaluationInterval}ç§’ã”ã¨ã«ç²¾åº¦å‘ä¸Šã®ãŸã‚å†è©•ä¾¡
            </p>
          )}
        </div>

        {/* éŒ²éŸ³è¨­å®š */}
        <div className="mt-4 pt-4 border-t border-[hsl(var(--border))]">
          <h3 className="text-xs font-medium text-[hsl(var(--muted-foreground))] flex items-center gap-1 mb-3">
            <Volume2 className="w-3 h-3" />
            éŒ²éŸ³è¨­å®š
          </h3>

          {/* éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰é¸æŠ */}
          <div className="flex items-center gap-4 mb-4">
            <span className="text-xs text-[hsl(var(--muted-foreground))]">éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰:</span>
            <div className="flex gap-2">
              <button
                onClick={() => setRecordingMode('vad')}
                disabled={isRecording}
                className={`px-3 py-1 rounded-md text-xs transition-colors ${
                  recordingMode === 'vad'
                    ? 'bg-purple-500 text-white'
                    : 'bg-[hsl(var(--secondary))] text-[hsl(var(--foreground))] hover:bg-[hsl(var(--secondary)/0.8)]'
                } disabled:opacity-50`}
              >
                ğŸ¤ éŸ³å£°æ¤œå‡º
              </button>
              <button
                onClick={() => setRecordingMode('fixed')}
                disabled={isRecording}
                className={`px-3 py-1 rounded-md text-xs transition-colors ${
                  recordingMode === 'fixed'
                    ? 'bg-purple-500 text-white'
                    : 'bg-[hsl(var(--secondary))] text-[hsl(var(--foreground))] hover:bg-[hsl(var(--secondary)/0.8)]'
                } disabled:opacity-50`}
              >
                â±ï¸ å›ºå®šæ™‚é–“
              </button>
            </div>
            {recordingMode === 'fixed' && (
              <div className="flex items-center gap-2">
                <input
                  type="range"
                  min="3"
                  max="30"
                  step="1"
                  value={fixedDuration}
                  onChange={(e) => setFixedDuration(parseInt(e.target.value))}
                  disabled={isRecording}
                  className="w-24 h-2 bg-[hsl(var(--secondary))] rounded-lg appearance-none cursor-pointer accent-purple-500 disabled:opacity-50"
                />
                <span className="text-xs font-mono text-[hsl(var(--foreground))] w-8">{fixedDuration}s</span>
              </div>
            )}
          </div>

          <div className="grid grid-cols-3 gap-4">
            {/* å…¥åŠ›ã‚²ã‚¤ãƒ³ */}
            <div className="space-y-1">
              <div className="flex justify-between items-center">
                <label className="text-xs text-[hsl(var(--muted-foreground))]">å…¥åŠ›ã‚²ã‚¤ãƒ³</label>
                <span className="text-xs font-mono text-[hsl(var(--foreground))]">{inputGain.toFixed(1)}x</span>
              </div>
              <input
                type="range"
                min="0.1"
                max="3.0"
                step="0.1"
                value={inputGain}
                onChange={(e) => setInputGain(parseFloat(e.target.value))}
                className="w-full h-2 bg-[hsl(var(--secondary))] rounded-lg appearance-none cursor-pointer accent-purple-500"
              />
              <div className="flex justify-between text-[10px] text-[hsl(var(--muted-foreground))]">
                <span>0.1x</span>
                <span>3.0x</span>
              </div>
            </div>

            {/* ç„¡éŸ³é–¾å€¤ - VADãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿è¡¨ç¤º */}
            {recordingMode === 'vad' && (
              <div className="space-y-1">
                <div className="flex justify-between items-center">
                  <label className="text-xs text-[hsl(var(--muted-foreground))]">ç„¡éŸ³é–¾å€¤</label>
                  <span className="text-xs font-mono text-[hsl(var(--foreground))]">{silenceThreshold}</span>
                </div>
                <input
                  type="range"
                  min="1"
                  max="100"
                  step="1"
                  value={silenceThreshold}
                  onChange={(e) => setSilenceThreshold(parseInt(e.target.value))}
                  className="w-full h-2 bg-[hsl(var(--secondary))] rounded-lg appearance-none cursor-pointer accent-purple-500"
                />
                <div className="flex justify-between text-[10px] text-[hsl(var(--muted-foreground))]">
                  <span>æ•æ„Ÿ</span>
                  <span>éˆæ„Ÿ</span>
                </div>
              </div>
            )}

            {/* ç„¡éŸ³ç¶™ç¶šæ™‚é–“ - VADãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿è¡¨ç¤º */}
            {recordingMode === 'vad' && (
              <div className="space-y-1">
                <div className="flex justify-between items-center">
                  <label className="text-xs text-[hsl(var(--muted-foreground))]">ç„¡éŸ³ç¶™ç¶šæ™‚é–“</label>
                  <span className="text-xs font-mono text-[hsl(var(--foreground))]">{(silenceDuration / 1000).toFixed(1)}s</span>
                </div>
                <input
                  type="range"
                  min="500"
                  max="5000"
                  step="100"
                  value={silenceDuration}
                  onChange={(e) => setSilenceDuration(parseInt(e.target.value))}
                  className="w-full h-2 bg-[hsl(var(--secondary))] rounded-lg appearance-none cursor-pointer accent-purple-500"
                />
                <div className="flex justify-between text-[10px] text-[hsl(var(--muted-foreground))]">
                  <span>0.5s</span>
                  <span>5.0s</span>
                </div>
              </div>
            )}
          </div>
        </div>
      </div>

      {/* Recording Controls */}
      <div className="p-6 border-b border-[hsl(var(--border))] flex flex-col items-center gap-4">
        <button
          onClick={isRecording ? stopRecording : startRecording}
          disabled={status === 'checking' || status === 'unavailable' || status === 'downloading'}
          className={`w-24 h-24 rounded-full flex items-center justify-center transition-all ${
            isRecording
              ? 'bg-red-500 hover:bg-red-600 animate-pulse'
              : 'bg-gradient-to-r from-purple-500 to-pink-500 hover:from-purple-600 hover:to-pink-600'
          } disabled:opacity-50 disabled:cursor-not-allowed`}
        >
          {isRecording ? (
            <MicOff className="w-10 h-10 text-white" />
          ) : (
            <Mic className="w-10 h-10 text-white" />
          )}
        </button>
        <p className="text-sm text-[hsl(var(--muted-foreground))]">
          {isRecording ? 'ã‚¿ãƒƒãƒ—ã—ã¦éŒ²éŸ³åœæ­¢' : 'ã‚¿ãƒƒãƒ—ã—ã¦éŒ²éŸ³é–‹å§‹'}
        </p>
        {isRecording && (
          <div className="w-full max-w-xs space-y-2">
            {/* å›ºå®šãƒ¢ãƒ¼ãƒ‰: ã‚¿ã‚¤ãƒãƒ¼ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ */}
            {recordingMode === 'fixed' && (
              <div className="flex items-center gap-2">
                <span className="text-xs text-[hsl(var(--muted-foreground))] w-12">é€²è¡Œ</span>
                <div className="flex-1 bg-[hsl(var(--secondary))] rounded-full h-3 overflow-hidden">
                  <div
                    className="h-3 rounded-full transition-all duration-1000 bg-gradient-to-r from-purple-500 to-pink-500"
                    style={{ width: `${(currentChunkTime / (enableProgressiveTranscription ? provisionalInterval : fixedDuration)) * 100}%` }}
                  />
                </div>
                <span className="text-xs font-mono text-[hsl(var(--foreground))] w-16 text-right">
                  {currentChunkTime}s / {enableProgressiveTranscription ? provisionalInterval : fixedDuration}s
                </span>
              </div>
            )}
            {/* éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒ¡ãƒ¼ã‚¿ãƒ¼ */}
            <div className="flex items-center gap-2">
              <span className="text-xs text-[hsl(var(--muted-foreground))] w-12">éŸ³å£°</span>
              <div className="flex-1 bg-[hsl(var(--secondary))] rounded-full h-3 overflow-hidden">
                <div
                  className={`h-3 rounded-full transition-all duration-75 ${
                    isSpeaking
                      ? 'bg-gradient-to-r from-green-500 to-emerald-400'
                      : 'bg-gradient-to-r from-gray-400 to-gray-500'
                  }`}
                  style={{ width: `${audioLevel}%` }}
                />
              </div>
              <span className={`text-xs w-16 text-right ${isSpeaking ? 'text-green-400' : 'text-[hsl(var(--muted-foreground))]'}`}>
                {isSpeaking ? 'ç™ºè©±ä¸­' : 'ç„¡éŸ³'}
              </span>
            </div>
            {/* èª¬æ˜ */}
            <p className="text-xs text-center text-[hsl(var(--muted-foreground))]">
              {recordingMode === 'vad'
                ? 'ç™ºè©±çµ‚äº†å¾Œã€è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™'
                : enableProgressiveTranscription
                  ? `${provisionalInterval}ç§’ã”ã¨ã«ä»®æ–‡å­—èµ·ã“ã— â†’ ${reEvaluationInterval}ç§’ã”ã¨ã«å†è©•ä¾¡`
                  : `${fixedDuration}ç§’ã”ã¨ã«è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹ã—ã¾ã™`}
            </p>
          </div>
        )}
      </div>

      {/* Main Content - 2 Column Layout */}
      <div className="flex-1 flex overflow-hidden">
        {/* Left Pane - Chunks */}
        <div className="flex-1 overflow-y-auto p-4 border-r border-[hsl(var(--border))]">
          {chunks.length === 0 ? (
            <div className="flex flex-col items-center justify-center h-full text-center">
              <Mic className="w-12 h-12 text-[hsl(var(--muted-foreground))] mb-4" />
              <p className="text-[hsl(var(--muted-foreground))]">
                éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã¨ã€ç™ºè©±ã‚’æ¤œå‡ºã—ã¦è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—â†’ç¿»è¨³ãŒå®Ÿè¡Œã•ã‚Œã¾ã™
              </p>
              {status === 'downloading' && (
                <div className="mt-4 p-4 bg-blue-500/10 border border-blue-500/20 rounded-lg text-sm text-blue-400 max-w-md">
                  <p className="font-medium mb-2">ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...</p>
                  {downloadProgress && (
                    <div className="space-y-2">
                      <div>
                        <div className="flex justify-between text-xs mb-1">
                          <span>ç¿»è¨³ãƒ¢ãƒ‡ãƒ«</span>
                          <span>{downloadProgress.translator}%</span>
                        </div>
                        <div className="w-full bg-blue-500/20 rounded-full h-2">
                          <div
                            className="bg-blue-500 h-2 rounded-full transition-all"
                            style={{ width: `${downloadProgress.translator}%` }}
                          />
                        </div>
                      </div>
                      <div>
                        <div className="flex justify-between text-xs mb-1">
                          <span>è¦ç´„ãƒ¢ãƒ‡ãƒ«</span>
                          <span>{downloadProgress.summarizer}%</span>
                        </div>
                        <div className="w-full bg-blue-500/20 rounded-full h-2">
                          <div
                            className="bg-blue-500 h-2 rounded-full transition-all"
                            style={{ width: `${downloadProgress.summarizer}%` }}
                          />
                        </div>
                      </div>
                    </div>
                  )}
                </div>
              )}
              {status === 'unavailable' && (
                <div className="mt-4 p-4 bg-red-500/10 border border-red-500/20 rounded-lg text-sm text-red-400 max-w-md">
                  <p className="font-medium mb-2">APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“</p>
                  <ul className="text-left list-disc list-inside space-y-1 text-xs">
                    <li>chrome://flags/#prompt-api-for-gemini-nano-multimodal-input â†’ Enabled</li>
                    <li>chrome://flags/#translation-api â†’ Enabled</li>
                    <li>chrome://flags/#summarization-api-for-gemini-nano â†’ Enabled</li>
                    <li>Chromeã‚’å†èµ·å‹•</li>
                  </ul>
                </div>
              )}
            </div>
          ) : (
            <div className="space-y-4">
              {chunks.map((chunk) => {
                const isProvisional = chunk.transcription.status === 'provisional';
                const isReEvaluating = chunk.transcription.status === 're-evaluating';

                return (
                  <div
                    key={chunk.id}
                    className={`p-4 rounded-lg border transition-all ${
                      isReEvaluating
                        ? 'bg-blue-500/10 border-blue-500/30 animate-pulse'
                        : isProvisional
                          ? 'bg-yellow-500/5 border-yellow-500/20 opacity-80'
                          : 'bg-[hsl(var(--card))] border-[hsl(var(--border))]'
                    }`}
                  >
                    <div className="flex items-center justify-between mb-3">
                      <div className="text-xs text-[hsl(var(--muted-foreground))]">
                        {chunk.timestamp.toLocaleTimeString('ja-JP')}
                      </div>
                      {/* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒƒã‚¸ */}
                      {enableProgressiveTranscription && (
                        <div className={`flex items-center gap-1 px-2 py-0.5 rounded-full text-[10px] ${
                          isReEvaluating
                            ? 'bg-blue-500/20 text-blue-400'
                            : isProvisional
                              ? 'bg-yellow-500/20 text-yellow-400'
                              : 'bg-green-500/20 text-green-400'
                        }`}>
                          {isReEvaluating ? (
                            <>
                              <RefreshCw className="w-2.5 h-2.5 animate-spin" />
                              å†è©•ä¾¡ä¸­
                            </>
                          ) : isProvisional ? (
                            <>
                              <Loader2 className="w-2.5 h-2.5" />
                              ä»®
                            </>
                          ) : (
                            <>
                              <CheckCircle2 className="w-2.5 h-2.5" />
                              ç¢ºå®š
                            </>
                          )}
                        </div>
                      )}
                    </div>

                    {/* æ–‡å­—èµ·ã“ã— */}
                    <div className="mb-3">
                      <div className="flex items-center gap-2 text-xs font-medium text-[hsl(var(--muted-foreground))] mb-1">
                        <Mic className="w-3 h-3" />
                        æ–‡å­—èµ·ã“ã—
                      </div>
                      {chunk.transcription.isProcessing ? (
                        <div className="flex items-center gap-2 text-[hsl(var(--muted-foreground))]">
                          <Loader2 className="w-4 h-4 animate-spin" />
                          <span className="text-sm">å‡¦ç†ä¸­...</span>
                        </div>
                      ) : chunk.transcription.error ? (
                        <p className="text-sm text-red-400">ã‚¨ãƒ©ãƒ¼: {chunk.transcription.error}</p>
                      ) : chunk.transcription.text ? (
                        <p className={`text-sm ${isProvisional ? 'text-[hsl(var(--muted-foreground))] italic' : 'text-[hsl(var(--foreground))]'}`}>
                          {chunk.transcription.text}
                        </p>
                      ) : (
                        <p className="text-sm text-[hsl(var(--muted-foreground))] italic">ï¼ˆéŸ³å£°ãªã—ï¼‰</p>
                      )}
                    </div>

                    {/* ç¿»è¨³ */}
                    <div>
                      <div className="flex items-center gap-2 text-xs font-medium text-[hsl(var(--muted-foreground))] mb-1">
                        <Languages className="w-3 h-3" />
                        ç¿»è¨³
                      </div>
                      {chunk.translation.isProcessing ? (
                        <div className="flex items-center gap-2 text-[hsl(var(--muted-foreground))]">
                          <Loader2 className="w-4 h-4 animate-spin" />
                          <span className="text-sm">å‡¦ç†ä¸­...</span>
                        </div>
                      ) : chunk.translation.error ? (
                        <p className="text-sm text-red-400">ã‚¨ãƒ©ãƒ¼: {chunk.translation.error}</p>
                      ) : chunk.translation.text ? (
                        <p className={`text-sm ${isProvisional ? 'text-[hsl(var(--muted-foreground))] italic' : 'text-[hsl(var(--foreground))]'}`}>
                          {chunk.translation.text}
                        </p>
                      ) : null}
                    </div>
                  </div>
                );
              })}
              <div ref={chunksEndRef} />
            </div>
          )}
        </div>

        {/* Right Pane - Overall Summaries */}
        {enableSummarization && (
        <div className="w-80 flex-shrink-0 overflow-y-auto p-4 bg-[hsl(var(--secondary)/0.3)]">
          {chunks.length === 0 ? (
            <div className="flex flex-col items-center justify-center h-full text-center">
              <FileText className="w-8 h-8 text-[hsl(var(--muted-foreground))] mb-2" />
              <p className="text-sm text-[hsl(var(--muted-foreground))] italic">
                éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã¨ã€ã“ã“ã«å…¨æ–‡ã®è¦ç´„ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
              </p>
            </div>
          ) : (
            <div className="space-y-4">
              {/* ç¿»è¨³ã®è¦ç´„ */}
              <div>
                <div className="flex items-center gap-2 text-sm font-medium text-[hsl(var(--foreground))] mb-2">
                  <Languages className="w-4 h-4" />
                  ç¿»è¨³ã®è¦ç´„
                </div>
                {translationSummary.isProcessing ? (
                  <div className="flex items-center gap-2 text-[hsl(var(--muted-foreground))]">
                    <Loader2 className="w-4 h-4 animate-spin" />
                    <span className="text-sm">è¦ç´„ã‚’ç”Ÿæˆä¸­...</span>
                  </div>
                ) : translationSummary.error ? (
                  <p className="text-sm text-red-400">ã‚¨ãƒ©ãƒ¼: {translationSummary.error}</p>
                ) : translationSummary.text ? (
                  <div className="p-3 rounded-lg bg-[hsl(var(--primary)/0.1)] border border-[hsl(var(--primary)/0.2)]">
                    <p className="text-sm text-[hsl(var(--foreground))] whitespace-pre-wrap">
                      {translationSummary.text}
                    </p>
                  </div>
                ) : (
                  <p className="text-sm text-[hsl(var(--muted-foreground))] italic">
                    ç¿»è¨³ãŒå®Œäº†ã™ã‚‹ã¨è¦ç´„ãŒç”Ÿæˆã•ã‚Œã¾ã™
                  </p>
                )}
              </div>

              {/* æ–‡å­—èµ·ã“ã—ã®è¦ç´„ */}
              <div>
                <div className="flex items-center gap-2 text-sm font-medium text-[hsl(var(--foreground))] mb-2">
                  <Mic className="w-4 h-4" />
                  æ–‡å­—èµ·ã“ã—ã®è¦ç´„ï¼ˆæ—¥æœ¬èªï¼‰
                </div>
                {transcriptionSummary.isProcessing ? (
                  <div className="flex items-center gap-2 text-[hsl(var(--muted-foreground))]">
                    <Loader2 className="w-4 h-4 animate-spin" />
                    <span className="text-sm">è¦ç´„ã‚’ç”Ÿæˆä¸­...</span>
                  </div>
                ) : transcriptionSummary.error ? (
                  <p className="text-sm text-red-400">ã‚¨ãƒ©ãƒ¼: {transcriptionSummary.error}</p>
                ) : transcriptionSummary.text ? (
                  <div className="p-3 rounded-lg bg-[hsl(var(--secondary))] border border-[hsl(var(--border))]">
                    <p className="text-sm text-[hsl(var(--foreground))] whitespace-pre-wrap">
                      {transcriptionSummary.text}
                    </p>
                  </div>
                ) : (
                  <p className="text-sm text-[hsl(var(--muted-foreground))] italic">
                    æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã™ã‚‹ã¨è¦ç´„ãŒç”Ÿæˆã•ã‚Œã¾ã™
                  </p>
                )}
              </div>
            </div>
          )}
        </div>
        )}
      </div>
    </div>
  );
}
